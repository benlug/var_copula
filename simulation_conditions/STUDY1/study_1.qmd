---
title: "Study 1: Comparative Performance of Gaussian and Skew-Normal Copula VAR Models Under Marginal Misspecification"
format:
  pdf:
    toc: true
    toc_depth: 3
execute:
  warning: false
  message: false
---

```{r setup}
#| label: setup
#| echo: false
suppressPackageStartupMessages({
  library(dplyr)
  library(tidyr)
  library(readr)
  library(ggplot2)
  library(stringr)
  library(knitr)
  library(RColorBrewer)
  library(sn)

  if (!requireNamespace("ggh4x", quietly = TRUE)) {
    message("Package 'ggh4x' not installed; proceeding without nested facets.")
  } else {
    library(ggh4x)
  }
  if (!requireNamespace("patchwork", quietly = TRUE)) {
    message("Package 'patchwork' is recommended for arranging plots.")
  } else {
    library(patchwork)
  }
})

# ---- paths ----
DATA_DIR <- file.path("data")
RES_DIR <- file.path("results")
EXPORT_DIR <- file.path(RES_DIR, "exported_tables")
dir.create(EXPORT_DIR, showWarnings = FALSE, recursive = TRUE)

files <- list(
  cond   = file.path(RES_DIR, "summary_conditions.csv"),
  rep    = file.path(RES_DIR, "summary_replications.csv"),
  design = file.path(DATA_DIR, "sim_conditions_singlelevel.rds")
)

if (!all(file.exists(unlist(files)))) {
  stop(
    "Missing required input files. Expected:\n",
    " - ", files$rep, "\n",
    " - ", files$cond, "\n",
    " - ", files$design, "\n",
    "Run the simulation pipeline and analysis script first."
  )
}
```

# 0. Summary

## 0.1 Computational Stability versus Statistical Inference

The Normal–Gaussian (NG) model demonstrates computational stability across all simulation conditions, with maximum $\hat{R} \leq 1.01$ in every replication and no divergent transitions. In contrast, the Skew–Gaussian (SG) model displays increasing sampling difficulty as marginal skewness intensifies. Under moderateSN, most runs converge successfully. Under strongSN, many runs exhibit elevated $\hat{R}$ values or divergences. Under extremeCHI, all runs are classified as “Problematic” (defined as $\hat{R} > 1.01$ or $n_{\text{div}} > 0$).

The relationship between MCMC diagnostics and statistical performance is more complex. Section 8 shows that, among successfully completed fits, Problematic runs do not consistently display greater bias or poorer coverage for the VAR dynamics ($\Phi$) compared to Clean runs. This indicates that, although diagnostics highlight computational challenges in the SG model’s posterior geometry, they do not reliably predict degraded inference for all parameters. In particular, the autoregressive coefficients appear robust to the sampling difficulties indicated by these diagnostics.

## 0.2 Model Performance Across Skewness Conditions

Under moderate skewness (moderateSN, $\alpha = \pm 4$), NG and SG demonstrate similar performance. For $T \geq 100$, bias is minimal, and coverage remains close to nominal for the primary parameters. At $T = 50$, both models exhibit mild finite-sample attenuation in certain $\Phi$ and $\rho$ parameters, due to prior regularization, estimation uncertainty, and errors-in-variables effects inherent to copula-based inference. These effects are minor and do not substantially impact coverage. At this skewness level, the additional marginal flexibility of SG does not provide inferential advantages, making NG preferable for computational efficiency.

With strong skewness (strongSN, $\alpha = \pm 9$), notable differences between NG and SG arise in the VAR dynamics. SG reduces relative bias in $\Phi$ by an average of approximately 0.04, with improvements up to 0.12 in specific cases, and converges more rapidly to true values as $T$ increases. Both models show downward bias in $\rho$. For NG, this bias results from marginal misspecification, while for SG, it is due to finite-sample challenges in estimating $\alpha$ (see Section 7.2). When $\hat{\alpha}$ is attenuated toward zero, the fitted CDF continues to deviate from the true distribution, causing PIT distortion and $\rho$ attenuation. As $T$ increases and $\alpha$ is more accurately estimated, this distortion decreases.

Under extreme misspecification (extremeCHI, standardized $\chi^2_1$ innovations), performance declines significantly, with distinct failure modes for specific parameters:

* For VAR dynamics ($\Phi$), SG demonstrates reduced bias and conservative (over-nominal) coverage for $T \geq 100$. In contrast, NG achieves coverage closer to nominal on average but displays greater bias and occasional undercoverage in the most challenging cases.
* For copula correlation ($\rho$), both models experience substantial attenuation resulting from PIT distortion caused by misspecified marginal CDFs. In a minority of replications, posterior means cross zero, leading to relative bias below $-1$.
* For intercepts ($\mu$), SG exhibits systematic bias (absolute bias up to approximately 0.36), whereas NG’s $\mu$ remains nearly unbiased. Under severe marginal misspecification, the fitted skew-normal likelihood cannot reproduce the bounded support and heavy tails of standardized $\chi^2_1$ innovations. In that setting, the SG fit may shift the conditional mean via $\mu$ to better align the centered skew-normal approximation with the bulk of the residual distribution.

## 0.3 Insights

PIT distortion induced by marginal CDF misspecification is the most prominent failure mechanism. When the assumed marginal CDF deviates from the truth, the probability integral transform yields non-uniform observations that compress tail co-movements toward the center of $[0, 1]^2$. This attenuates the effective dependence visible to the Gaussian copula and can induce sign reversals in $\hat{\rho}$ under extreme mismatch.

Under extremeCHI, the SG model’s intercept estimates shift away from zero. This is consistent with $\mu$ acting as a location adjustment in the pseudo-true SG fit under misspecification—improving the centered skew-normal approximation to the residual bulk and partially insulating $\Phi$—while leaving PIT distortion (and thus $\rho$ attenuation) fundamentally unchanged.


A finding is that standard MCMC diagnostics ($\hat{R}$, divergences) primarily index computational difficulty in exploring the SG posterior under strong skewness, but do not reliably predict inferential failure for all parameters. In particular, the VAR coefficients exhibit similar coverage in Clean and Problematic subsets, suggesting that flagged runs may still yield valid inference for dynamics while other parameters (notably $\rho$ under misspecification) fail regardless of diagnostic status.

# 1. Introduction

This simulation study evaluates the performance of two Bayesian Vector Autoregressive (VAR(1)) models: a standard Normal-Gaussian (NG) model and a Skew-Gaussian (SG) model. The analysis examines how these models recover the true parameters when the data generating process (DGP) exhibits varying degrees of skewness in the innovations, coupled via a Gaussian copula.

## 1.1. Data Generating Process (DGP)

The DGP is a bivariate VAR(1) model:

$$
Y_t = \mu + \Phi Y_{t-1} + \epsilon_t
$$

Where $Y_t$ is a 2x1 vector of observations, $\mu$ is the intercept vector (set to 0 in this simulation), $\Phi$ is the 2x2 matrix of autoregressive coefficients, and $\epsilon_t$ is the 2x1 vector of innovations (errors).

The innovations $\epsilon_t = (\epsilon_{1,t}, \epsilon_{2,t})^T$ are generated to be standardized.

::: {.callout-note}
## Standardization of the innovations

We require innovations $\epsilon_t = (\epsilon_{1,t}, \epsilon_{2,t})^\top$ to have $\mathbb{E}[\epsilon_{i,t}] = 0$ and $\text{Var}(\epsilon_{i,t}) = 1$ for all conditions. This is enforced in the DGP, and the fitted models are parameterized to be consistent with this convention.

**Skew-Normal marginals (DGP and SG model)** Let $\text{SN}(\xi, \omega, \alpha)$ denote the skew-normal with location $\xi$, scale $\omega > 0$, shape $\alpha$.

$$
\delta = \frac{\alpha}{\sqrt{1 + \alpha^2}}
$$

Moments:

$$
\mu_{\text{SN}} = \xi + \omega \delta \sqrt{\frac{2}{\pi}}, \quad \sigma^2_{\text{SN}} = \omega^2\left(1 - \frac{2\delta^2}{\pi}\right)
$$

To ensure mean 0 and variance 1, select

$$
\omega = \left(1 - \frac{2\delta^2}{\pi}\right)^{-\frac{1}{2}}, \quad \xi = -\omega \delta \sqrt{\frac{2}{\pi}}
$$

In the DGP (for moderateSN and strongSN), $\alpha$ is set to $\pm 4$ or $\pm 9$, $\delta$ is computed, and $\omega$ and $\xi$ are determined using the formulas above to ensure that draws from $\text{SN}(\xi, \omega, \alpha)$ are standardized.

In the SG model, a centered parameterization is employed to re-express the SN such that the innovation has zero theoretical mean by construction. In practice, the Stan parameters are $(\delta, \omega)$ (or equivalent reparameterizations), and the implied $\xi$ is the value that centers the innovation at 0, as described above. Consequently, the SG model cannot use $\mu$ to absorb a nonzero innovation mean; $\mu$ therefore represents the VAR intercept (process mean) rather than a marginal location parameter.

**Chi-squared marginals (DGP and NG/SG models)** For $\chi^2_\nu$: $\mathbb{E} = \nu$, $\text{Var} = 2\nu$, skewness $\gamma_1 = \sqrt{8/\nu}$, excess kurtosis $\gamma_2 = 12/\nu$. In the DGP (for extremeCHI), we standardize after simulating: if $X \sim \chi^2_1$, set

$$
Z = \frac{X - 1}{\sqrt{2}},
$$

and, if left skew is required, mirror as $-Z$; in the copula DGP, this is implemented via $Q_{-X}(u) = -Q_X(1 - u)$ so the copula parameter is preserved.

Thus, $Z$ has mean 0 and variance 1 but remains skewed ($\gamma_1 \approx 2.83$) and heavy-tailed ($\gamma_2 = 12$). In the NG model, innovations are Gaussian with scale $\sigma$. Since the data are standardized, the true value is $\sigma = 1$; deviations from 1 indicate misspecification.

In the SG model, innovations remain skew-normal with zero mean by construction, using $(\delta, \omega)$. Under a $\chi^2$ DGP, this results in misspecified marginals; the parameter $\alpha$ adjusts shape flexibly but cannot match $\chi^2_1$ skewness.
:::

<!-- ::: {.callout-note} -->
<!-- ## SG Model Parameterization: Variance Not Fixed -->

<!-- The SG model estimates both scale ($\omega$) and shape ($\delta$) parameters without constraining the innovation variance to equal 1. This apparent overparameterization is justified for several reasons: -->

<!-- 1. **Bayesian identification:** In a Bayesian framework with proper priors on both $\omega$ and $\delta$, the posterior remains well-defined even without fixing variance. The data jointly inform both parameters, and the priors regularize the solution. -->

<!-- 2. **Practical flexibility:** Fixing $\omega = f(\delta)$ to enforce unit variance would reduce model flexibility and could cause numerical issues when $|\delta| \to 1$ (where $\omega \to \infty$). The free parameterization avoids these boundary complications. -->

<!-- 3. **Prior-induced regularization:** The half-normal prior on $\omega$ (centered near 1) and the normal prior on $\delta$ (centered at 0) together induce a prior on innovation variance that concentrates around reasonable values without hard constraints. -->

<!-- 4. **Robustness to misspecification:** When the true DGP is not skew-normal (e.g., extremeCHI), the model can adjust both shape and scale to best approximate the data, rather than being forced into a potentially poor fit by the unit-variance constraint. -->
<!-- ::: -->

The joint distribution of $\epsilon_t$ is modeled using a Gaussian Copula, parameterized by the correlation coefficient $\rho$. This approach enables the dependence structure to be modeled independently of the marginal distributions $f_i(\epsilon_{i,t})$. The joint density is specified by Sklar's theorem:

$$
f(\epsilon_{1,t}, \epsilon_{2,t}) = c(u_{1,t}, u_{2,t}; \rho) \cdot f_1(\epsilon_{1,t}) \cdot f_2(\epsilon_{2,t})
$$

$$
f(\epsilon_{1,t}, \epsilon_{2,t}) = c_{\text{Gauss}}(F_1(\epsilon_{1,t}), F_2(\epsilon_{2,t}); \rho) \cdot \frac{2}{\omega_1}\phi\left(\frac{\epsilon_{1,t} - \xi_1}{\omega_1}\right)\Phi\left(\alpha_1 \frac{\epsilon_{1,t} - \xi_1}{\omega_1}\right) \cdot \frac{2}{\omega_2}\phi\left(\frac{\epsilon_{2,t} - \xi_2}{\omega_2}\right)\Phi\left(\alpha_2 \frac{\epsilon_{2,t} - \xi_2}{\omega_2}\right)
$$

The marginal distributions $f_i$ are varied to introduce distinct levels and types of skewness.

::: {.callout-important}
## Copula Sign Under Mirroring (Preserved via $Q_{-X}$)

Left-skew margins are produced by mirroring standardized innovations. In the DGP, mirroring is implemented via the quantile function of $-X$,

$$
Q_{-X}(u) = -Q_X(1 - u),
$$

which is monotone increasing in $u$. This preserves the Gaussian copula parameter $\rho$ even in mixed-direction cells.
:::

<!-- ::: {.callout-note} -->
<!-- ## Numerical Stability in Copula Evaluation -->

<!-- The Gaussian copula density requires evaluating $\Phi^{-1}(u)$, where $u = F(\epsilon)$ is the probability integral transform. When $u$ approaches 0 or 1, $\Phi^{-1}(u)$ diverges to $\pm\infty$, resulting in numerical overflow. To prevent this, boundary clamping is applied: -->

<!-- $$ -->
<!-- u_{\text{clamped}} = \max(\varepsilon, \min(1 - \varepsilon, u)), \quad \varepsilon = 10^{-9} -->
<!-- $$ -->

<!-- This clamping affects only the most extreme quantiles (beyond the 0.9999999th percentile) and has a negligible impact on inference. The choice of $\varepsilon = 10^{-9}$ balances numerical stability against loss of tail information. Values smaller than $10^{-12}$ risk floating-point underflow, while values larger than $10^{-6}$ would noticeably compress the effective copula support. -->
<!-- ::: -->

## 1.2. Simulation Design

The study employs a full factorial design crossing five factors, resulting in 108 unique conditions and 200 replications per condition.

```{r design_table}
#| label: design_table
#| echo: false

design_summary <- tibble(
  Factor = c(
    "Time Series Length (T)",
    "Copula Correlation ($\\rho$)",
    "VAR Parameters ($\\Phi$)",
    "",
    "Skewness Level (Marginals)",
    "",
    "",
    "Skewness Direction"
  ),
  Levels = c(
    "50, 100, 200",
    "0.30, 0.50",
    "Set A (Symmetric): $\\begin{pmatrix} 0.40 & 0.10 \\\\ 0.10 & 0.40 \\end{pmatrix}$",
    "Set B (Asymmetric): $\\begin{pmatrix} 0.55 & 0.10 \\\\ 0.10 & 0.25 \\end{pmatrix}$",
    "moderateSN: Skew-Normal (SN), shape $\\alpha = \\pm 4$",
    "strongSN: SN, shape $\\alpha = \\pm 9$",
    "extremeCHI: Standardized Chi-squared ($\\chi^2_1$)",
    "`++` (both positive), `--` (both negative), `+-` (mixed; `-+` omitted)"
  )
)

kable(design_summary, caption = "Summary of the Simulation Design Factors.", escape = FALSE)
```

::: {.callout-note}
## Exclusion of -+ Direction

The design includes directions `++`, `--`, and `+-`, while omitting `-+` to reduce computational cost.

- For VAR Set A ($\phi_{11} = \phi_{22}$ and $\phi_{12} = \phi_{21}$), relabeling $Y_1 \leftrightarrow Y_2$ leaves the DGP invariant. Under this symmetry, `+-` and `-+` are exactly equivalent, and including both would be redundant.

- For VAR Set B, the cross-effects remain symmetric ($\phi_{12} = \phi_{21}$), but the diagonal dynamics differ ($\phi_{11} \neq \phi_{22}$). Swapping $Y_1$ and $Y_2$ therefore also swaps $\phi_{11}$ and $\phi_{22}$; `-+` is not strictly identical to `+-` within the same VAR-Set-B condition.

Accordingly, mixed-direction results for Set B should be interpreted qualitatively, such as patterns in PIT distortion and $\rho$ attenuation, rather than as an exact surrogate for the omitted `-+` case.
:::

## 1.3. True Parameter Values

```{r true_params_table}
#| label: true_params_table
#| echo: false

true_params <- tibble(
  Parameter = c(
    "$\\mu_1, \\mu_2$",
    "$\\phi_{11}$ (Set A / Set B)",
    "$\\phi_{12} = \\phi_{21}$",
    "$\\phi_{22}$ (Set A / Set B)",
    "$\\rho$",
    "$\\sigma_1, \\sigma_2$ (NG model)",
    "$\\alpha$ (moderateSN)",
    "$\\alpha$ (strongSN)",
    "$\\omega$ (moderateSN)",
    "$\\omega$ (strongSN)",
    "$\\alpha, \\omega$ (extremeCHI)"
  ),
  `True Value` = c(
    "0, 0",
    "0.40 / 0.55",
    "0.10",
    "0.40 / 0.25",
    "0.30 or 0.50",
    "1.0, 1.0",
    "$\\pm 4$ (direction-dependent)",
    "$\\pm 9$ (direction-dependent)",
    "1.5795",
    "1.6415",
    "Not applicable (misspecified)"
  ),
  Notes = c(
    "Innovations are mean-zero",
    "Diagonal AR coefficients",
    "Cross-effects (symmetric)",
    "Diagonal AR coefficients",
    "Copula correlation",
    "Innovations are unit-variance",
    "$\\delta \\approx \\pm 0.970$",
    "$\\delta \\approx \\pm 0.994$",
    "Derived from $\\alpha = \\pm 4$",
    "Derived from $\\alpha = \\pm 9$",
    "SG parameters have no true counterpart"
  )
)

kable(true_params, caption = "True Parameter Values Used in the Data Generating Process.", escape = FALSE)
```

::: {.callout-note}
## Interpreting SG Parameters Under extremeCHI

For the extremeCHI condition, the DGP uses standardized $\chi^2_1$ marginals, not skew-normal. Therefore, the SG model parameters ($\alpha$, $\omega$) have no "true" values in the conventional sense. Any estimate represents the model's best skew-normal approximation to a non-skew-normal distribution.

In the analysis, these truth values are set to NA and excluded from bias and coverage calculations. When interpreting SG model fits under extremeCHI, the estimated $\alpha$ and $\omega$ should be understood as:

- $\alpha$: The skewness direction and magnitude that best approximates $\chi^2_1$ within the skew-normal family (expected to be large and positive for right-skewed conditions)
- $\omega$: The scale adjustment needed to match the variance given the fitted shape

These estimates reflect approximation quality rather than parameter recovery.
:::

::: {.callout-note}
## Bias Metric for Intercepts ($\mu$)

The "Relative Bias" plots display `mean_rel_bias`, defined as:

$$
\text{Relative Bias} = \frac{\hat{\theta} - \theta_{\text{true}}}{|\theta_{\text{true}}|}
$$

However, for the intercept parameters $\mu_1$ and $\mu_2$, the true value is zero, making relative bias undefined. In these cases, we report absolute bias instead:

$$
\text{Bias}_\mu = \hat{\mu} - 0 = \hat{\mu}
$$

This means that for $\mu$ panels in "Relative Bias" plots, the y-axis shows absolute deviation from zero (in original units), not a proportion. Cross-parameter comparisons should account for this difference in scale interpretation.
:::

## 1.4 Visual Check: Standardized Marginal Innovations (DGP)

```{r dgp_marginal_distributions, fig.width=10, fig.height=8}
#| label: dgp_marginal_distributions
#| echo: false

# SN parameters that enforce mean 0 and var 1 for a given alpha
sn_params <- function(alpha) {
  delta <- alpha / sqrt(1 + alpha^2)
  omega <- sqrt(1 / (1 - 2 * delta^2 / pi)) # Var = 1
  xi <- -omega * delta * sqrt(2 / pi) # Mean = 0
  list(xi = xi, omega = omega, alpha = alpha)
}

set.seed(2025)

# standardized chi-square draws (df = 1), both right-skewed and mirrored
rchisq_std <- function(n, df = 1, mirror = FALSE) {
  x <- stats::rchisq(n, df = df)
  z <- (x - df) / sqrt(2 * df) # mean 0, var 1
  if (mirror) -z else z
}

# 20k draws per margin
draws <- list(
  "SN alpha = +4" = sn::rsn(20000, xi = sn_params(+4)$xi, omega = sn_params(+4)$omega, alpha = +4),
  "SN alpha = -4" = sn::rsn(20000, xi = sn_params(-4)$xi, omega = sn_params(-4)$omega, alpha = -4),
  "SN alpha = +9" = sn::rsn(20000, xi = sn_params(+9)$xi, omega = sn_params(+9)$omega, alpha = +9),
  "SN alpha = -9" = sn::rsn(20000, xi = sn_params(-9)$xi, omega = sn_params(-9)$omega, alpha = -9),
  "Chi-square df=1 (std., right)" = rchisq_std(20000, df = 1, mirror = FALSE),
  "Chi-square df=1 (std., mirrored)" = rchisq_std(20000, df = 1, mirror = TRUE)
)

df_m <- dplyr::bind_rows(lapply(names(draws), function(nm) {
  tibble::tibble(value = draws[[nm]], dist = nm)
}))

# palette
pal <- c(
  "SN alpha = +4" = "#1b9e77",
  "SN alpha = -4" = "#1b9e77",
  "SN alpha = +9" = "#d95f02",
  "SN alpha = -9" = "#d95f02",
  "Chi-square df=1 (std., right)" = "#7570b3",
  "Chi-square df=1 (std., mirrored)" = "#7570b3"
)

ggplot(df_m, aes(value)) +
  geom_histogram(aes(y = after_stat(density), fill = dist),
    bins = 60, alpha = 0.25, colour = NA
  ) +
  geom_density(aes(colour = dist), linewidth = 0.8) +
  # N(0,1) reference
  stat_function(fun = dnorm, linewidth = 0.7, linetype = "dashed") +
  geom_vline(xintercept = 0, linetype = "dotted") +
  scale_fill_manual(values = pal, guide = "none") +
  scale_colour_manual(values = pal, name = "") +
  facet_wrap(~dist, scales = "free", ncol = 2) +
  theme_bw(base_size = 10) +
  labs(
    title = "Standardized marginal innovations used in the DGP",
    x = "value", y = "density"
  )
```

# 2. Data Loading and Preparation

```{r data_prep}
#| label: data_prep
#| echo: false


# load the design grid
design <- readRDS(files$design) |>
  select(condition_id, skew_level, direction, T, rho, VARset)

# load condition-level summary (aggregated metrics)
cond_raw <- read_csv(files$cond, show_col_types = FALSE) |>
  left_join(design, by = "condition_id")

# load replication-level summary (individual runs)
# NOTE: keep rows with param = NA so that failed fits (status != "ok") are
# retained for MCMC-status summaries and replication-count tables.
rep_raw <- read_csv(files$rep, show_col_types = FALSE) |>
  left_join(design, by = "condition_id")

# define parameter order and groups
param_levels <- c(
  "omega[1]", "omega[2]", "alpha[1]", "alpha[2]",
  "sigma[1]", "sigma[2]",
  "mu[1]", "mu[2]",
  "phi11", "phi12", "phi21", "phi22", "rho"
)

# apply factor levels and clearer labels
prep_data <- function(df) {
  df |>
    mutate(
      param = factor(param, levels = param_levels),
      T = factor(T),
      skew_level = factor(skew_level, levels = c("moderateSN", "strongSN", "extremeCHI")),
      rho_val = rho, # keep numeric rho
      VARset_val = VARset, # keep character VARset
      rho = factor(rho, labels = sort(unique(df$rho))),
      VARset = factor(VARset, labels = sort(unique(df$VARset))),
      Model = factor(ifelse(model == "SG", "SG", "NG"),
        levels = c("NG", "SG")
      )
    )
}

cond <- prep_data(cond_raw)
rep_df <- prep_data(rep_raw)

# Mirroring preserves the copula parameter, so no rho sign adjustment is needed.

cond <- cond |>
  mutate(
    # use coalesce to handle NA emp_sd if N_valid < 2
    RMSE = sqrt(mean_bias^2 + coalesce(emp_sd^2, 0))
  )

# separate core parameters (VAR dynamics, intercepts, correlation)
core_params <- c("mu[1]", "mu[2]", "phi11", "phi12", "phi21", "phi22", "rho")
```

## 2.1. MCMC Classification and Overview

Runs are classified according to MCMC diagnostics, and computational performance is summarized. A replication run is designated as "Problematic" if it completes sampling but meets either of the following criteria:

- **High R-hat:** The potential scale reduction factor (max_rhat) for any parameter was greater than 1.01.
- **Divergent Transitions:** The sampler reported one or more divergent transitions (n_div > 0) after warmup (if recorded).

```{r mcmc_classification}
#| label: mcmc_classification
#| echo: false


RHAT_THRESHOLD <- 1.01
has_divs <- any(!is.na(rep_df$n_div))

rep_df <- rep_df |>
  mutate(
    mcmc_status = case_when(
      is.na(max_rhat) | status != "ok" ~ "Failed/Error",
    # classification based on Rhat and divergent transitions (if available)
    max_rhat > RHAT_THRESHOLD | (has_divs & n_div > 0) ~ "Problematic",
      TRUE ~ "Clean"
    ),
    mcmc_status = factor(mcmc_status, levels = c("Clean", "Problematic", "Failed/Error"))
  )

# MCMC Overview Plot (Status Counts)
mcmc_summary <- rep_df |>
  distinct(condition_id, rep_id, Model, mcmc_status, T, skew_level) |>
  group_by(Model, T, skew_level, mcmc_status) |>
  summarise(Count = n(), .groups = "drop")
```

```{r mcmc_status_plot, fig.height=6, fig.width=10}
#| label: mcmc_status_plot
#| echo: false

ggplot(mcmc_summary, aes(x = T, y = Count, fill = mcmc_status)) +
  geom_bar(stat = "identity", position = "stack") +
  facet_grid(Model ~ skew_level) +
  labs(
    x = "Time Series Length (T)", y = "Number of Replications", fill = "MCMC Status",
    title = "MCMC Convergence Status by Condition"
  ) +
  theme_bw(base_size = 14) +
  scale_fill_manual(values = c("Clean" = "#4daf4a", "Problematic" = "#ff7f00", "Failed/Error" = "#e41a1c"))
```

**Interpretation:** NG fits are consistently classified as Clean across all experimental conditions, which reflects the well-behaved posterior geometry of Gaussian marginals. In contrast, SG sampling performance declines as marginal skewness increases: most runs are Clean under moderateSN, Problematic rates are moderate under strongSN, and under extremeCHI. Notably, as demonstrated in Section 8, the Problematic classification does not strongly predict degraded inference for the VAR dynamics ($\Phi$), indicating that sampling difficulties are primarily confined to the marginal parameter space.

```{r mcmc_divergences_plot, fig.height=6, fig.width=10}
#| label: mcmc_divergences_plot
#| echo: false

if (has_divs) {
  # MCMC Overview Plot (Distribution of Divergent Transitions)
  div_dist_data <- rep_df |>
    filter(param == "rho") |>
    distinct(condition_id, rep_id, Model, T, skew_level, n_div, mcmc_status) |>
    filter(mcmc_status != "Failed/Error")

  ggplot(div_dist_data, aes(x = T, y = n_div, fill = Model)) +
    geom_boxplot(outlier.shape = NA, alpha = 0.6, position = position_dodge(width = 0.8)) +
    geom_point(size = 1.5, alpha = 0.4, position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.8)) +
    facet_grid(Model ~ skew_level) +
    theme_bw(base_size = 14) +
    labs(
      title = "Distribution of Divergent Transitions (Post-Warmup) per Replication",
      y = "Count of Divergences (n_div)",
      x = "Time Points (T)"
    )
} else {
  cat("Divergent transition counts were not recorded for this render.")
}
```

**Interpretation:** When divergence counts are available, NG demonstrates nearly zero divergences across all conditions, which is consistent with the well-behaved geometry of Gaussian marginals. The SG model, however, displays increasing divergence counts as marginal skewness intensifies, reflecting the challenging posterior geometry near parameter boundaries as $|\delta|$ approaches 1. Under extremeCHI, divergence counts are both higher and more variable. Nevertheless, as shown in Section 8, these divergences do not strongly correlate with inferential quality for the VAR dynamics, suggesting that divergences primarily indicate geometric difficulty in the marginal parameter space rather than a failure of global posterior approximation.

<!-- ## 2.2. Failure-Inclusive Summary (SG, extremeCHI) -->

<!-- The SG success rate under extremeCHI and the conditional coverage among successful fits are reported. Failure-inclusive coverage is calculated by treating failed fits as non-coverage, multiplying the success rate by the conditional coverage. -->

<!-- # ```{r sg_extremechi_failure_summary} -->
<!-- # #| label: sg_extremechi_failure_summary -->
<!-- # #| echo: false -->
<!-- #  -->
<!-- # sg_fit_status <- rep_df |> -->
<!-- #   distinct(condition_id, rep_id, Model, status, T, skew_level) |> -->
<!-- #   filter(Model == "SG", skew_level == "extremeCHI") -->
<!-- #  -->
<!-- # sg_success_rate <- mean(sg_fit_status$status == "ok") -->
<!-- #  -->
<!-- # sg_failure_summary <- rep_df |> -->
<!-- #   filter(Model == "SG", skew_level == "extremeCHI", status == "ok", param %in% core_params) |> -->
<!-- #   group_by(param) |> -->
<!-- #   summarise( -->
<!-- #     conditional_coverage = mean(cover95, na.rm = TRUE), -->
<!-- #     .groups = "drop" -->
<!-- #   ) |> -->
<!-- #   mutate( -->
<!-- #     success_rate = sg_success_rate, -->
<!-- #     failure_inclusive_coverage = success_rate * conditional_coverage -->
<!-- #   ) -->
<!-- #  -->
<!-- # knitr::kable( -->
<!-- #   sg_failure_summary, -->
<!-- #   digits = 3, -->
<!-- #   caption = "SG extremeCHI: success rate and conditional coverage (failure-inclusive)." -->
<!-- # ) -->
<!-- # ``` -->

```{r helpers}
#| label: helpers
#| echo: false


# standardized visualization settings
theme_standard <- theme_bw(base_size = 14) # to increase base font size
dodge_width <- 0.3

# helper function for plotting metrics across conditions
plot_metric <- function(data, metric_col, ylab, title, use_free_y = FALSE, ylims = NULL) {
  # filter out potential NAs (e.g. if N_truth_avail = 0)
  data_filtered <- data |> filter(!is.na(.data[[metric_col]]))

  if (nrow(data_filtered) == 0) {
    message("Skipping plot '", title, "' due to missing data.")
    return(NULL)
  }

  p <- ggplot(data_filtered, aes(x = T, y = .data[[metric_col]], color = Model, group = Model)) +
    geom_line(position = position_dodge(dodge_width), linewidth = 1) +
    geom_point(position = position_dodge(dodge_width), size = 2.5) +
    # labeller = label_both correctly adds the variable name (VARset, rho) and the value.
    facet_grid(param ~ direction + VARset + rho, labeller = label_both, scales = ifelse(use_free_y, "free_y", "fixed")) +
    theme_standard +
    labs(title = title, y = ylab, x = "Time Points (T)")

  # add reference lines based on the metric
  if (metric_col %in% c("mean_rel_bias", "sd_bias")) {
    p <- p + geom_hline(yintercept = 0, linetype = "dashed", color = "darkgrey")
  } else if (metric_col == "coverage_95") {
    p <- p + geom_hline(yintercept = 0.95, linetype = "dashed", color = "darkgrey")
  }

  # apply custom Y-axis limits if provided
  if (!is.null(ylims)) {
    p <- p + coord_cartesian(ylim = ylims)
  }

  return(p)
}

# Summarise conditions using the reported metrics (no rho adjustment)
summarise_conditions <- function(df) {
  df |>
    filter(!is.na(param)) |>
    group_by(Model, T, skew_level, direction, VARset, rho, param) |>
    summarise(
      mean_rel_bias = mean(rel_bias, na.rm = TRUE),
      coverage_95 = mean(cover95, na.rm = TRUE),
      mean_post_sd = mean(post_sd, na.rm = TRUE),
      emp_sd = sd(post_mean, na.rm = TRUE),
      mean_bias = mean(bias, na.rm = TRUE),
      N_valid = n(),
      .groups = "drop"
    ) |>
    mutate(
      emp_sd = if_else(is.na(emp_sd), 0, emp_sd),
      sd_bias = mean_post_sd - emp_sd,
      RMSE = sqrt(mean_bias^2 + emp_sd^2)
    )
}

# wrapper to filter data and call the plotting function for a specific skew level
generate_plots_for_condition <- function(skew_lvl, data_cond) {
  data_subset <- data_cond |>
    filter(skew_level == skew_lvl, param %in% core_params)

  # Adjust Y-axis limits for coverage based on the condition severity
  cov_ylims <- if (skew_lvl == "extremeCHI") c(0.5, 1.0) else c(0.8, 1.0)

  list(
    # Metric: Relative Bias
    bias = plot_metric(data_subset, "mean_rel_bias", "Mean Relative Bias",
      paste("Relative Bias (DGP:", skew_lvl, ")"),
      use_free_y = TRUE
    ),
    # Metric: 95% CI Coverage
    coverage = plot_metric(data_subset, "coverage_95", "Empirical Coverage",
      paste("95% Coverage (DGP:", skew_lvl, ")"),
      ylims = cov_ylims
    ),
    # Metric: RMSE (Overall Accuracy)
    rmse = plot_metric(data_subset, "RMSE", "Root Mean Squared Error",
      paste("RMSE (DGP:", skew_lvl, ")"),
      use_free_y = TRUE
    ),
    # Metric: Posterior SD (Uncertainty Estimate)
    post_sd = plot_metric(data_subset, "mean_post_sd", "Mean Posterior SD",
      paste("Mean Posterior SD (DGP:", skew_lvl, ")"),
      use_free_y = TRUE
    ),
    # Metric: SD-Bias (Calibration of Uncertainty)
    sdbias = plot_metric(data_subset, "sd_bias", "SD-Bias",
      paste("SD-Bias (DGP:", skew_lvl, ")"),
      use_free_y = TRUE
    )
  )
}
```

```{r compute_condition_summaries}
#| label: compute_condition_summaries
#| echo: false


# Compute condition-level summaries (no rho sign adjustment)
cond_summary <- rep_df |>
  filter(mcmc_status != "Failed/Error") |>
  summarise_conditions()
```

# 4. Condition 1: Moderate Skewness (moderateSN)

DGP: Skew-Normal innovations ($\alpha = 4$). NG model is misspecified; SG model is correctly specified.

```{r plots_moderateSN}
#| label: plots_moderateSN

plots_mod <- generate_plots_for_condition("moderateSN", cond_summary)
```

## 4.1. Relative Bias (moderateSN)

```{r moderateSN_bias, fig.height=12, fig.width=14}
#| label: moderateSN_bias
#| echo: false

print(plots_mod$bias)
```

## 4.2. 95% Coverage (moderateSN)

```{r moderateSN_coverage, fig.height=12, fig.width=14}
#| label: moderateSN_coverage
#| echo: false

print(plots_mod$coverage)
```

## 4.3. SD-Bias (moderateSN)

```{r moderateSN_sdbias, fig.height=12, fig.width=14}
#| label: moderateSN_sdbias
#| echo: false

# Note: RMSE and Mean Posterior SD plots are omitted for brevity, focusing on Bias, Coverage, and SD-Bias.
print(plots_mod$sdbias)
```

Under conditions of moderate skewness ($\alpha = \pm 4$), the NG and SG models exhibit comparable performance. Bias remains minimal across all parameters, and coverage consistently approaches 0.95 for most scenarios. Some modest finite-sample attenuation is observed in certain $\Phi$ and $\rho$ estimates at $T = 50$, but this effect largely dissipates when $T \geq 100$. The SD-bias for both models is nearly zero, which suggests that posterior uncertainty quantification is well-calibrated.

From a practical perspective, this scenario constitutes a benign misspecification regime in which the level of skewness does not substantially affect the validity of the Gaussian marginal assumption. The increased complexity of the SG model, such as higher computational demands and slightly elevated rates of sampling difficulties, is not warranted by significant inferential improvements. Therefore, in applications where true innovation skewness is anticipated to be mild, the NG model offers a simpler and equally effective alternative.

# 5. Condition 2: Strong Skewness (strongSN)

DGP: Skew-Normal innovations ($\alpha = 9$). The misspecification for the NG model is severe.

```{r plots_strongSN}
#| label: plots_strongSN

plots_strong <- generate_plots_for_condition("strongSN", cond_summary)
```

## 5.1. Relative Bias (strongSN)

```{r strongSN_bias, fig.height=12, fig.width=14}
#| label: strongSN_bias
#| echo: false

print(plots_strong$bias)
```

## 5.2. 95% Coverage (strongSN)

```{r strongSN_coverage, fig.height=12, fig.width=14}
#| label: strongSN_coverage
#| echo: false

print(plots_strong$coverage)
```

## 5.3. SD-Bias (strongSN)

```{r strongSN_sdbias, fig.height=12, fig.width=14}
#| label: strongSN_sdbias
#| echo: false

print(plots_strong$sdbias)
```

Under strong skewness ($\alpha = \pm 9$), differences between the NG and SG models become evident for the VAR dynamics, although these differences remain modest in absolute terms. The SG model reduces relative bias in $\Phi$ by approximately 0.04 on average, with cell-specific improvements reaching up to 0.12 in the most favorable cases. Both models achieve near-nominal coverage for most parameters when sampling converges successfully.

The copula correlation $\rho$ demonstrates downward bias under both models, but for distinct mechanistic reasons. In the NG model, this bias results from marginal misspecification: the Gaussian CDF does not capture skew-normal tails, which distorts the PIT and attenuates estimated dependence. In the SG model, although the marginal specification is correct, the shape parameter $\alpha$ is difficult to estimate accurately when $T$ is small. The posterior for $\alpha$ is attenuated toward zero, resulting in a fitted CDF that deviates from the true distribution and induces similar PIT distortion. As $T$ increases and $\alpha$ becomes more accurately identified, this finite-sample effect diminishes.

SD-bias remains small for both models across parameters, indicating that posterior uncertainty quantification is well-calibrated even under pronounced skewness. The computational cost of the SG model, including elevated $\hat{R}$ and occasional divergences in some cells, may not be justified for short time series where the shape parameter is poorly identified. For longer series ($T \geq 200$), the advantages of the SG model in $\Phi$ estimation become more pronounced.

# 6. Condition 3: Extreme Skewness and Misspecification (extremeCHI)

DGP: standardized chi-squared ($df = 1$) innovations. Both models are marginally misspecified; SG allows skewness in the innovations but remains outside the $\chi^2_1$ family.

```{r plots_extremeCHI}
#| label: plots_extremeCHI

plots_extreme <- generate_plots_for_condition("extremeCHI", cond_summary)
```

## 6.1. Relative Bias (extremeCHI)

```{r extremeCHI_bias, fig.height=12, fig.width=14}
#| label: extremeCHI_bias
#| echo: false

print(plots_extreme$bias)
```

Interpretation: Substantial Bias in SG Model Intercepts ($\mu_1$, $\mu_2$)

A notable characteristic of extremeCHI is the systematic bias observed in the SG intercepts ($\mu_1$, $\mu_2$), whereas the NG intercepts remain approximately zero.

- NG: Despite strong misspecification in higher moments (skewness, kurtosis), the DGP innovations are standardized to have mean zero. The NG model’s posterior for $\mu$ remains centered near zero because $\mu$ is primarily identified by the sample mean of the implied innovations. Misspecification is expressed elsewhere—most prominently through PIT distortion and the resulting attenuation of the fitted copula dependence parameter $\rho$.

- SG: In the centered skew-normal parameterization, the innovation distribution is mean-zero by construction for any $(\delta, \omega)$ (because $\xi$ is a deterministic centering function of $(\delta,\omega)$). Under extremeCHI, however, standardized $\chi^2_1$ marginals are far outside the skew-normal family (notably due to bounded support and heavy right tails). In this regime, the fitted SG model is necessarily a misspecified approximation, and the posterior concentrates around a *pseudo-true* parameter vector that best matches the observed residual distribution. One manifestation is that $\mu$ may shift away from 0 to relocate the conditional mean so that the centered skew-normal likelihood better matches the bulk of the misspecified residuals. This can reduce pressure on $\Phi$ at the cost of biased intercept inference.

This adjustment in $\mu$ does not mitigate copula attenuation. The parameter $\rho$ remains severely biased in both models because PIT distortion results from CDF misspecification in the tails, a phenomenon independent of intercept adjustments.

### Follow-on diagnostic: Intercept shift vs. marginal approximation (SG, extremeCHI)

To make the intercept-as-location-adjustment explicit, @fig-mu-marginals plots the SG posterior mean intercept for each margin against the corresponding marginal shape and scale estimates ($\alpha_i$, $\omega_i$) across replications under extremeCHI. 

```{r extremeCHI_mu_vs_marginals, fig.height=6, fig.width=10}
#| label: fig-mu-marginals
#| echo: false

# One row per replication with the relevant SG posterior means
sg_extreme <- rep_df |>
  dplyr::filter(
    Model == "SG",
    skew_level == "extremeCHI",
    mcmc_status != "Failed/Error",
    param %in% c("mu[1]","mu[2]","alpha[1]","alpha[2]","omega[1]","omega[2]")
  ) |>
  dplyr::mutate(
    param_clean = dplyr::recode(as.character(param),
      "mu[1]"="mu1", "mu[2]"="mu2",
      "alpha[1]"="alpha1", "alpha[2]"="alpha2",
      "omega[1]"="omega1", "omega[2]"="omega2"
    )
  ) |>
  dplyr::select(condition_id, rep_id, T, direction, rho_val, VARset_val, mcmc_status, param_clean, post_mean) |>
  tidyr::pivot_wider(names_from = param_clean, values_from = post_mean)

# Margin-specific skew sign (+/-) extracted from the direction label
sg_extreme_long <- dplyr::bind_rows(
  sg_extreme |>
    dplyr::mutate(margin = "1", skew_sign = substr(as.character(direction), 1, 1)) |>
    dplyr::transmute(condition_id, rep_id, T, direction, skew_sign, rho_val, VARset_val, mcmc_status,
                     margin, mu = mu1, alpha = alpha1, omega = omega1),
  sg_extreme |>
    dplyr::mutate(margin = "2", skew_sign = substr(as.character(direction), 2, 2)) |>
    dplyr::transmute(condition_id, rep_id, T, direction, skew_sign, rho_val, VARset_val, mcmc_status,
                     margin, mu = mu2, alpha = alpha2, omega = omega2)
)

plot_df <- sg_extreme_long |>
  tidyr::pivot_longer(cols = c(alpha, omega), names_to = "marg_param", values_to = "x")

ggplot(plot_df, aes(x = x, y = mu, color = skew_sign)) +
  geom_point(alpha = 0.25, size = 1.5) +
  geom_smooth(method = "loess", se = FALSE, linewidth = 1) +
  facet_grid(margin ~ marg_param, scales = "free_x") +
  theme_standard +
  labs(
    title = "SG (extremeCHI): Intercept shift vs. marginal shape/scale across replications",
    subtitle = "Each point is a replication; columns show alpha vs omega; rows show margin 1 vs margin 2.",
    x = "Posterior mean of marginal parameter",
    y = "Posterior mean of mu (intercept)",
    color = "Skew sign (by margin)"
  )
```

In extremeCHI, the SG posterior means exhibit a strong replication-level dependency between the intercept ($\mu_i$) and the marginal scale ($\omega_i$), with the direction of this dependency reversing with the skew sign. This indicates that, under severe marginal misspecification, the SG intercept is functioning as a location adjustment that compensates for limitations of the skew-normal approximation, rather than recovering the true process intercept (which is zero in the DGP).

::: {.callout-note}
The extremeCHI condition uses standardized Chi-squared innovations with 1 degree of freedom ($\chi^2(1)$). The mismatch between this DGP and the model assumptions is strong:

| Distribution | Theoretical Skewness | Theoretical Excess Kurtosis |
|-------------|---------------------|---------------------------|
| True DGP ($\chi^2(1)$) | $\approx 2.83$ | 12 |
| NG Model (Normal) | 0 | 0 |
| SG Model (Skew-Normal Max) | $\approx 0.995$ | $\approx 0.869$ |
:::

::: {.callout-note}
## Skewness and kurtosis formulas

- $\chi^2_\nu$: $\mathbb{E} = \nu$, $\text{Var} = 2\nu$, $\gamma_1 = \sqrt{8/\nu}$, $\gamma_2 = 12/\nu$ (excess). For $\nu = 1$: $\gamma_1 \approx 2.828$, $\gamma_2 = 12$.

- Skew-normal $\text{SN}(\xi, \omega, \alpha)$: with $\delta = \alpha/\sqrt{1 + \alpha^2}$,

$$
\mu = \xi + \omega \delta \sqrt{\frac{2}{\pi}}, \quad \sigma^2 = \omega^2\left(1 - \frac{2\delta^2}{\pi}\right),
$$

$$
\gamma_1 = \frac{(4 - \pi)}{2} \frac{(\delta\sqrt{2/\pi})^3}{(1 - 2\delta^2/\pi)^{3/2}}, \quad \gamma_2 = 2(\pi - 3) \frac{(\delta\sqrt{2/\pi})^4}{(1 - 2\delta^2/\pi)^2}.
$$

As $|\alpha| \to \infty$ (i.e., $|\delta| \to 1$), the maximum skewness is $\gamma_1 \approx 0.995$ and the maximum excess kurtosis is $\gamma_2 \approx 0.869$.
:::

Mechanism: PIT distortion under marginal misspecification. The probability integral transform (PIT) maps each margin $Y$ to $U = F_{\text{assumed}}(Y)$. If $F_{\text{assumed}} = F_{\text{true}}$, then $U$ follows a uniform distribution on $(0, 1)$. Under misspecification:

- Tail compression: If the true data exhibit heavier right tails (such as $\chi^2_1$) than the assumed skew-normal or normal distribution, then very large $Y$ values do not map near 1 after transformation. Instead, they are pulled toward the center (for example, $U \approx 0.8$ instead of 0.98). Left tails experience analogous distortion under mirroring.

- Rank distortion: The PIT serves as a ranking mechanism. By compressing true extremes toward the center, co-extreme events ($Y_1$, $Y_2$) that genuinely move together in the tails no longer co-locate in the corners of $[0, 1]^2$; instead, they are mapped to the interior.

In Gaussian copulas, dependence is most apparent in the corners. When misspecified marginals shift probability mass away from the corners, the copula detects less tail co-movement, even if such dependence exists in the data. Consequently, any fitted $\rho$ is reduced. This pattern is evident in the $\rho$ relative-bias panels.

Mechanism: attenuation of $\rho$. The joint likelihood factorizes as follows:

$$
\prod_t c(U_{1,t}, U_{2,t}; \rho) f_1(y_{1,t}) f_2(y_{2,t}),
$$

Thus, only the copula term $c(\cdot ; \rho)$ can adjust dependence. When the PIT transformation pushes tail pairs $(U_{1,t}, U_{2,t})$ toward the center (approximately $0.5, 0.5$), the Gaussian copula density becomes less sensitive to $\rho$, as the score in $\rho$ flattens. To avoid penalizing improbable tail corners that the distorted $(U_1, U_2)$ no longer occupy, the posterior shifts $\rho$ toward zero. This results in a large negative relative bias and sub-nominal coverage for $\rho$ in extremeCHI, regardless of whether the MCMC status is "Clean" or "Problematic".

## 6.2. 95% Coverage (extremeCHI)

```{r extremeCHI_coverage, fig.height=12, fig.width=14}
#| label: extremeCHI_coverage
#| echo: false

print(plots_extreme$coverage)
```

## 6.3. SD-Bias (extremeCHI)

```{r extremeCHI_sdbias, fig.height=12, fig.width=14}
#| label: extremeCHI_sdbias
#| echo: false

print(plots_extreme$sdbias)
```

**Interpretation (extremeCHI):** Severe marginal misspecification leads to distinct failure modes across parameters, and neither model yields universally satisfactory inference.

- **NG:** The intercepts $\mu_1, \mu_2$ remain approximately unbiased because, despite misspecification in higher moments, the DGP innovations have mean zero by construction and the NG model's location parameters absorb this correctly. However, $\Phi$ and especially $\rho$ exhibit substantial bias. Coverage for $\Phi$ is close to nominal on average but decreases in specific cells; for $\rho$, coverage falls well below nominal and some replications show posterior means that cross zero (relative bias $< -1$).

- **SG:** The VAR dynamics $\Phi$ are comparatively robust, exhibiting smaller bias than the NG model, but coverage is conservative (often exceeding 0.99 for $T \geq 100$), which indicates overly wide posterior intervals. The intercepts $\mu_1, \mu_2$ are systematically biased because the centered skew-normal parameterization cannot approximate $\chi^2_1$ tails; the model compensates by shifting $\mu$ away from zero. The copula correlation $\rho$ remains severely attenuated, with performance comparable to the NG model.

The shared failure for $\rho$ confirms that PIT distortion is the fundamental problem: both normal and skew-normal CDFs misrepresent $\chi^2_1$ tail probabilities, compressing co-extreme events toward the center of the copula and forcing $\hat{\rho}$ downward. This effect is largely independent of MCMC diagnostic status; $\rho$ attenuation occurs in both Clean and Problematic runs because it reflects statistical misspecification rather than computational failure.

SD-bias for the dynamic parameters ($\Phi$) is often close to zero even under extreme misspecification, indicating that posterior uncertainty for these parameters can remain reasonably calibrated. This decoupling, in which $\Phi$ inference is preserved while $\rho$ and $\mu$ fail, illustrates the parameter-specific nature of misspecification consequences in copula-based VAR models.

<!-- ## 6.4. PIT Distortion Evidence (NG) and $\rho$ Attenuation -->

<!-- To link PIT distortion to $\rho$ attenuation, we compute a simple PIT diagnostic under the NG marginal assumption. For a random subset of simulated series per skew regime, we apply the standard Normal CDF to the true residuals and report the KS statistic against Uniform(0, 1). We then compare this PIT distortion to the average $\rho$ relative bias for NG. -->

<!-- ```{r pit_vs_rho, fig.height=4.5, fig.width=7} -->
<!-- #| label: pit_vs_rho -->
<!-- #| echo: false -->

<!-- set.seed(2025) -->
<!-- pit_sample_n <- 30 -->

<!-- data_files <- list.files(DATA_DIR, "^sim_data_cond\\d+_rep\\d+\\.rds$", full.names = TRUE) -->
<!-- meta <- stringr::str_match(basename(data_files), "cond(\\d+)_rep(\\d+)") -->

<!-- file_df <- tibble::tibble( -->
<!--   path = data_files, -->
<!--   condition_id = as.integer(meta[, 2]) -->
<!-- ) |> -->
<!--   left_join(design, by = "condition_id") -->

<!-- sampled_files <- file_df |> -->
<!--   group_by(skew_level) |> -->
<!--   group_modify(~ dplyr::slice_sample(.x, n = min(pit_sample_n, nrow(.x)))) |> -->
<!--   ungroup() -->

<!-- compute_pit_ks <- function(path) { -->
<!--   dat <- readRDS(path) -->
<!--   y <- as.matrix(dat$data[, c("y1", "y2")]) -->
<!--   phi <- dat$true_params$phi -->
<!--   mu <- dat$true_params$mu -->

<!--   if (nrow(y) < 2) return(NA_real_) -->

<!--   pred <- matrix(mu, nrow = nrow(y) - 1, ncol = 2, byrow = TRUE) + y[1:(nrow(y) - 1), ] %*% t(phi) -->
<!--   res <- y[2:nrow(y), ] - pred -->

<!--   u1 <- stats::pnorm(res[, 1]) -->
<!--   u2 <- stats::pnorm(res[, 2]) -->

<!--   ks1 <- suppressWarnings(stats::ks.test(u1, "punif")$statistic) -->
<!--   ks2 <- suppressWarnings(stats::ks.test(u2, "punif")$statistic) -->

<!--   mean(c(ks1, ks2)) -->
<!-- } -->

<!-- pit_stats <- sampled_files |> -->
<!--   mutate(pit_ks = vapply(path, compute_pit_ks, numeric(1))) |> -->
<!--   group_by(skew_level) |> -->
<!--   summarise(pit_ks = mean(pit_ks, na.rm = TRUE), .groups = "drop") -->

<!-- rho_bias_ng <- cond_summary |> -->
<!--   filter(Model == "NG", param == "rho") |> -->
<!--   group_by(skew_level) |> -->
<!--   summarise(rho_bias = mean(mean_rel_bias, na.rm = TRUE), .groups = "drop") -->

<!-- pit_link <- pit_stats |> -->
<!--   left_join(rho_bias_ng, by = "skew_level") |> -->
<!--   mutate(skew_level = factor(skew_level, levels = c("moderateSN", "strongSN", "extremeCHI"))) -->

<!-- ggplot(pit_link, aes(x = pit_ks, y = rho_bias, label = skew_level)) + -->
<!--   geom_point(size = 3, color = "#1b9e77") + -->
<!--   geom_text(nudge_y = 0.02, size = 3) + -->
<!--   theme_bw(base_size = 12) + -->
<!--   labs( -->
<!--     title = "PIT Distortion (NG) vs. rho Attenuation", -->
<!--     x = "Mean KS statistic for PIT (Normal CDF)", -->
<!--     y = "Mean relative bias of rho (NG)" -->
<!--   ) -->
<!-- ``` -->

<!-- ```{r pit_vs_rho_table} -->
<!-- #| label: pit_vs_rho_table -->
<!-- #| echo: false -->

<!-- knitr::kable( -->
<!--   pit_link, -->
<!--   digits = 3, -->
<!--   caption = "PIT distortion and rho attenuation by skew regime (NG)." -->
<!-- ) -->
<!-- ``` -->

# 7. Marginal Parameters

We examine the parameters governing the marginal distributions to understand the mechanisms driving the results.

## 7.1. NG Scale Parameter Behavior ($\sigma$)

The innovations are standardized to unit variance. Under correct specification, the NG model should recover $\sigma = 1$.

```{r ng_sigma_bias, fig.height=6, fig.width=14}
#| label: ng_sigma_bias
#| echo: false

sigma_data <- cond_summary |>
  filter(param %in% c("sigma[1]", "sigma[2]"), Model == "NG")

# We plot the absolute bias (mean_bias) here as the truth is 1.
ggplot(sigma_data, aes(x = T, y = mean_bias, color = skew_level, group = skew_level)) +
  geom_line(position = position_dodge(0.3), linewidth = 1) +
  geom_point(position = position_dodge(0.3), size = 2.5) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "darkgrey") +
  facet_grid(param ~ direction + VARset + rho, labeller = label_both) +
  theme_standard +
  labs(
    title = "NG Model: Bias for Sigma (Truth=1)",
    y = "Mean Bias (Estimate - 1)",
    x = "Time Points (T)",
    color = "DGP Skew Level"
  )
```

The $\sigma$ estimates under the NG model exhibit small yet systematic deviations from the true value of 1 (bias $\approx \pm 0.025$). These deviations result from marginal misspecification. When the NG model encounters skewed or heavy-tailed innovations, it is unable to capture the shape mismatch and consequently makes minor adjustments to the scale parameter.

It is important to note that $\sigma$ bias does not drive $\rho$ attenuation. Both phenomena originate from the same underlying cause, marginal misspecification, but occur through distinct mechanisms.

* $\sigma$ bias: The NG model makes slight adjustments to the scale parameter to improve marginal likelihood when applied to non-Gaussian data. This adjustment is a localized response with minimal impact on other parameters.
* $\rho$ attenuation: This phenomenon arises from PIT distortion. Regardless of the fit of the marginal density, if the marginal cumulative distribution function (CDF) misrepresents tail probabilities, the copula receives distorted inputs. Even with perfect estimation of $\sigma$, the PIT would still compress tail observations toward the center of $[0, 1]^2$, thereby attenuating the perceived dependence.

The relatively small magnitude of $\sigma$ bias ($\approx 2.5\%$) compared to the substantial $\rho$ bias (often exceeding 100\%) demonstrates that these are parallel consequences of misspecification, rather than a causal sequence in which $\sigma$ error propagates to $\rho$.

## 7.2. SG Shape Parameter Recovery ($\alpha$)

We examine how well the SG model recovers the true shape parameter $\alpha$ (applicable for SN conditions).

```{r sg_alpha_bias, fig.height=6, fig.width=14}
#| label: sg_alpha_bias
#| echo: false

alpha_data <- cond_summary |>
  filter(
    param %in% c("alpha[1]", "alpha[2]"),
    Model == "SG",
    skew_level %in% c("moderateSN", "strongSN")
  )

# Filter NAs in case truth was unavailable
alpha_data <- alpha_data |> filter(!is.na(mean_rel_bias))

if (nrow(alpha_data) > 0) {
  ggplot(alpha_data, aes(x = T, y = mean_rel_bias, color = skew_level, group = skew_level)) +
    geom_line(position = position_dodge(0.3), linewidth = 1) +
    geom_point(position = position_dodge(0.3), size = 2.5) +
    geom_hline(yintercept = 0, linetype = "dashed", color = "darkgrey") +
    ggh4x::facet_nested(param ~ direction + VARset + rho, labeller = label_both, scales = "free_y") +
    theme_standard +
    labs(
      title = "SG Model: Relative Bias for Alpha (Shape Parameter)",
      y = "Relative Bias",
      x = "Time Points (T)",
      color = "DGP Skew Level"
    )
}
```

**Interpretation (shape recovery).** Under correctly specified SN DGPs, posterior means for $\alpha$ are biased toward 0 at $T = 50$, with substantially reduced bias at $T \geq 100$. 

::: {.callout-important}
## Caveat: Large $|\alpha|$ is weakly identified at short $T$

For $|\alpha| \in \{4, 9\}$, the transformed shape parameter $\delta = \alpha/\sqrt{1 + \alpha^2}$ approaches the boundary $\pm 1$. In this regime, $\alpha$ and $\omega$ are strongly confounded, and the likelihood provides limited information about the exact magnitude of $\alpha$ at $T = 50$. With regularizing priors, posterior estimates may shrink toward 0 even under correct specification. The observed downward bias in $|\alpha|$ at $T = 50$ should therefore be interpreted primarily as finite-sample regularization, rather than as a failure to recover the direction of skewness.
:::

Even when $|\alpha|$ is underestimated at $T = 50$, the sign is typically correct, which partially aligns the PIT with the data. This partial correction is consistent with the small bias and near-nominal coverage for $\Phi$ under SG in the SN DGPs, as well as with the improvement in $\Phi$ performance as $T$ increases and $\alpha$ becomes better identified.

# 8. Impact of MCMC Diagnostics

The SG model frequently encountered "Problematic" MCMC runs. We investigate if the statistical performance differs between "Clean" and "Problematic" runs for the SG model.

```{r aggregate_by_status}
#| label: aggregate_by_status
#| echo: false

# Helper function to re-aggregate metrics, filtering by MCMC status
# It is crucial to recalculate Empirical SD, SD-Bias, and RMSE within the subgroups.
aggregate_by_status <- function(df) {
  df |>
    # Filter out total failures
    filter(mcmc_status != "Failed/Error", !is.na(param)) |>
    group_by(condition_id, Model, param, mcmc_status, T, skew_level, direction, VARset, rho, rho_val, VARset_val) |>
    summarise(
      N_valid = n(),
      mean_rel_bias = mean(rel_bias, na.rm = TRUE),
      coverage_95 = mean(cover95, na.rm = TRUE),
      # Recalculate components for SD-Bias and RMSE within the status group
      mean_post_sd = mean(post_sd, na.rm = TRUE),
      emp_sd = sd(post_mean, na.rm = TRUE),
      mean_bias = mean(bias, na.rm = TRUE),
      .groups = "drop"
    ) |>
    mutate(
      # Handle cases where N_valid=1, leading to NA emp_sd
      emp_sd = ifelse(is.na(emp_sd), 0, emp_sd),
      sd_bias = mean_post_sd - emp_sd,
      RMSE = sqrt(mean_bias^2 + emp_sd^2)
    )
}

cond_status <- aggregate_by_status(rep_df)
```

## 8.1. Coverage Split by MCMC Status (SG Model)

We visualize the coverage across all three conditions, comparing Clean vs. Problematic runs.

```{r coverage_status_split, fig.height=10, fig.width=10}
#| label: coverage_status_split
#| echo: false

status_comparison_data <- cond_status |>
  filter(
    Model == "SG",
    param %in% core_params
  )

# We focus the visualization on the interaction between T, Status, and Skew Level
# We average over VARset, rho, and direction for a clearer overview
status_overview <- status_comparison_data |>
  group_by(T, param, skew_level, mcmc_status) |>
  summarise(mean_coverage = mean(coverage_95, na.rm = TRUE), .groups = "drop")

ggplot(
  status_overview,
  aes(x = T, y = mean_coverage, color = mcmc_status, group = mcmc_status)
) +
  geom_line(position = position_dodge(0.3), linewidth = 1) +
  geom_point(position = position_dodge(0.3), size = 2.5) +
  geom_hline(yintercept = 0.95, linetype = "dashed", color = "darkgrey") +
  # Facet by parameter and skew level
  facet_grid(param ~ skew_level) +
  theme_standard +
  labs(
    title = "SG Model Coverage: Clean vs. Problematic Runs Across Conditions",
    y = "Average Empirical Coverage",
    x = "Time Points (T)",
    color = "MCMC Status"
  ) +
  coord_cartesian(ylim = c(0.8, 1.0))
```

**Interpretation: Impact of MCMC Status** Across the full design, SG coverage for the VAR coefficients ($\Phi$) remains highly consistent between Clean and Problematic subsets. In contrast, parameters that are fundamentally impacted by marginal misspecification (notably $\rho$ under extremeCHI) do not show meaningful improvement when restricting to Clean runs, which is consistent with statistical rather than computational failure.

Because the SG diagnostic flags are expected to originate primarily in the marginal parameterization (i.e., the bounded skewness reparameterization and associated scale), we next repeat the status-split coverage analysis for the SG marginal parameters ($\alpha$, $\omega$) under the skew-normal DGP conditions where these parameters have well-defined ground truth.

This finding has a significant methodological implication: standard MCMC diagnostics are sensitive indicators of computational difficulty but are imperfect predictors of inferential quality. The diagnostic criteria applied in this study ($\hat{R} > 1.01$, $n_{\text{div}} > 0$) effectively identify runs where the sampler encountered difficulties with the SG posterior geometry, typically due to the skew-normal parameterization driving $|\delta|$ toward boundary values. However, these computational challenges do not consistently result in degraded inference. The VAR dynamics demonstrate robustness to the specific posterior geometry issues identified by these diagnostics, whereas parameters more directly involved in the challenging geometry ($\alpha$, $\omega$, and by extension $\rho$ through the PIT) may be affected regardless of whether diagnostics are triggered.

## 8.1.1 Coverage Split by MCMC Status (SG Marginal Parameters)

This diagnostic repeats the Clean vs. Problematic comparison for the SG marginal parameters $\alpha$ and $\omega$ (restricted to moderateSN/strongSN where the DGP is skew-normal and truth is defined).

```{r coverage_status_split_marginals, fig.height=8, fig.width=10}
#| label: coverage_status_split_marginals
#| echo: false

marginal_params <- c("alpha[1]", "alpha[2]", "omega[1]", "omega[2]")

marg_status_data <- cond_status |>
  dplyr::filter(
    Model == "SG",
    param %in% marginal_params,
    skew_level %in% c("moderateSN", "strongSN")
  )

marg_overview <- marg_status_data |>
  dplyr::group_by(T, param, skew_level, mcmc_status) |>
  dplyr::summarise(mean_coverage = mean(coverage_95, na.rm = TRUE), .groups = "drop")

ggplot(
  marg_overview,
  aes(x = T, y = mean_coverage, color = mcmc_status, group = mcmc_status)
) +
  geom_line(position = position_dodge(0.3), linewidth = 1) +
  geom_point(position = position_dodge(0.3), size = 2.5) +
  geom_hline(yintercept = 0.95, linetype = "dashed", color = "darkgrey") +
  facet_grid(param ~ skew_level) +
  theme_standard +
  labs(
    title = "SG Marginal-Parameter Coverage: Clean vs. Problematic Runs",
    y = "Average Empirical Coverage",
    x = "Time Points (T)",
    color = "MCMC Status"
  ) +
  coord_cartesian(ylim = c(0.8, 1.0))
```

* Unlike ($\Phi$) (where Clean vs Problematic coverage is very similar), the marginal parameters ($\alpha$) and ($\omega$) show sensitivity to MCMC status.
* This supports the claim that R-hat/divergences are primarily indexing difficulty in the SG marginal-parameter subspace, even when ($\Phi$) inference remains comparatively stable.

## 8.2. Relationship between Bias and Divergences

We examine if runs with more divergences exhibit higher bias at the replication level. We focus on the SG model under strongSN conditions (only when divergence counts are available).

```{r bias_vs_divergences, fig.height=12, fig.width=12}
#| label: bias_vs_divergences
#| echo: false

if (has_divs) {
  div_bias_data <- rep_df |>
    filter(
      Model == "SG",
      skew_level == "strongSN",
      param %in% core_params,
      mcmc_status != "Failed/Error"
    ) |>
    mutate(abs_bias = abs(bias))

  # Use absolute bias for comparison
  ggplot(div_bias_data, aes(x = n_div, y = abs_bias)) +
    geom_point(alpha = 0.3, position = position_jitter(width = 0.2), size = 2) +
    # Use a generalized additive model (gam) for smoothing to capture non-linear relationships
    geom_smooth(method = "gam", color = "red", linewidth = 1.5) +
    facet_grid(param ~ T, scales = "free") +
    theme_standard +
    labs(
      title = "Absolute Bias vs. Divergences (SG Model, strongSN)",
      x = "Number of Divergent Transitions (n_div)",
      y = "Absolute Bias"
    )
} else {
  cat("Divergence counts were not recorded for this render; skipping this diagnostic.")
}
```

In the SG model under strongSN, replication-level absolute bias for the core parameters shows no monotone relationship with the number of post-warmup divergent transitions. Runs with few or zero divergences can still exhibit large bias, while many runs with substantial divergence counts remain low-bias; correspondingly, the smoothed trends are largely flat and any apparent slopes are weak and parameter-specific rather than systematic. Substantively, this implies that divergences are flagging local posterior-geometry difficulties (likely concentrated in the skew-normal marginal subspace) rather than reliably indicating degraded posterior-mean accuracy for the VAR dynamics or copula correlation; so screening runs solely by n_div would discard many accurate fits and retain some biased ones. 


<!-- This pattern admits several interpretations: -->

<!-- 1. **Divergences index geometric difficulty, not inferential failure for all parameters.** The skew-normal parameterization creates challenging posterior curvature near parameter boundaries ($|\delta| \rightarrow 1$), which triggers divergences. However, the VAR coefficients $\Phi$ occupy a different region of parameter space and may be largely insulated from this geometry—their bias is determined primarily by data informativeness and prior regularization, not by whether the sampler encountered difficulties in other parameters. -->

<!-- 2. **Marginal misspecification dominates over sampling error for $\rho$.** The large biases observed in $\rho$ under strongSN and extremeCHI reflect PIT distortion from CDF misspecification, not MCMC approximation error. A run with perfect sampling (zero divergences, $\hat{R} = 1.00$) would still produce attenuated $\hat{\rho}$ because the statistical model is misspecified—the problem is in the likelihood, not the sampler. -->

<!-- 3. **Divergence counts are a crude metric.** Not all divergences are equally consequential; a handful early in post-warmup may have minimal impact on posterior summaries, while systematic divergences in a particular region of parameter space may cause severe bias without generating high total counts. -->

# 10. Details

This section provides technical details on the implementation of the simulation study, including prior specifications, MCMC settings, and mathematical derivations.

## 10.1. Prior Specifications

Both models use weakly informative priors designed to regularize estimates while allowing the data to dominate inference. The priors are summarized in the following tables.

**Table: Prior Specifications for the Normal-Gaussian (NG) Model**

| Parameter | Prior | Support | Rationale |
|-----------|-------|---------|-----------|
| $\mu_1, \mu_2$ | $\text{Normal}(0, 1)$ | $\mathbb{R}$ | Weakly informative; centered at true value (0) |
| $\phi_{11}, \phi_{12}, \phi_{21}, \phi_{22}$ | $\text{Normal}(0, 0.5)$ | $(-1, 1)$ | Regularizes toward stationarity; truncated by bounds |
| $\sigma_1, \sigma_2$ | $\text{Half-Normal}(0, 1)$ | $(0, \infty)$ | Weakly informative scale prior; mode near 0, mass around 1 |
| $\rho$ | $\text{Normal}(0, 0.5)$ | $(-1, 1)$ | Regularizes toward independence; truncated by bounds |

**Table: Prior Specifications for the Skew-Normal-Gaussian (SG) Model**

| Parameter | Prior | Support | Rationale |
|-----------|-------|---------|-----------|
| $\mu_1, \mu_2$ | $\text{Normal}(0, 1)$ | $\mathbb{R}$ | Weakly informative; centered at true value (0) |
| $\phi_{11}, \phi_{12}, \phi_{21}, \phi_{22}$ | $\text{Normal}(0, 0.5)$ | $(-1, 1)$ | Regularizes toward stationarity; truncated by bounds |
| $\omega_1, \omega_2$ | $\text{Half-Normal}(0, 1)$ | $(0, \infty)$ | Scale parameter; concentrates mass near 1 |
| $\delta_1, \delta_2$ | $\text{Normal}(0, 0.5)$ | $(-1, 1)$ | Regularizes toward symmetry ($\delta = 0$); truncated by bounds |
| $\rho$ | $\text{Normal}(0, 0.5)$ | $(-1, 1)$ | Regularizes toward independence; truncated by bounds |

<!-- ::: {.callout-note} -->
<!-- ## Half-Normal Priors -->

<!-- For parameters constrained to be positive (e.g., $\sigma$, $\omega$), Stan automatically truncates the normal distribution at 0, yielding a half-normal prior. A $\text{Half-Normal}(0, 1)$ prior has mode 0, mean $\sqrt{2/\pi} \approx 0.80$, and standard deviation $\sqrt{1 - 2/\pi} \approx 0.60$. -->
<!-- ::: -->

## 10.2. MCMC Settings

All models were fitted using NUTS implemented in Stan via the `rstan` package. The following settings were used:

**Table: MCMC Sampling Configuration**

| Setting | Value | Description |
|---------|-------|-------------|
| Chains | 4 | Number of independent Markov chains |
| Total iterations | 4,000 | Iterations per chain (including warmup) |
| Warmup iterations | 2,000 | Discarded adaptation period |
| Post-warmup draws | 2,000 | Retained samples per chain |
| `adapt_delta` | 0.95 | Target acceptance probability (higher = smaller step size) |
| `max_treedepth` | 15 | Maximum tree depth for NUTS |
| Parallelization | Outer loop | Replications parallelized; chains run sequentially |

::: {.callout-note}
## Convergence Diagnostics

A replication was classified as **Problematic** if either:

- Maximum $\hat{R} > 1.01$ across all parameters, or
- Number of post-warmup divergent transitions $n_{\text{div}} > 0$ (when recorded)

An `adapt_delta = 0.95` was chosen to reduce divergent transitions in the SG model, which exhibits more challenging posterior geometry due to the skew-normal parameterization.
:::

## 10.3. Gaussian Copula Log-Density

The Gaussian copula density for uniform marginals $(u, v) \in (0,1)^2$ with correlation parameter $\rho \in (-1, 1)$ is implemented as follows.

Let $z_1 = \Phi^{-1}(u)$ and $z_2 = \Phi^{-1}(v)$ denote the standard normal quantile transforms. The copula log-density is:

$$
\log c(u, v; \rho) = -\frac{1}{2}\log(1 - \rho^2) - \frac{1}{2(1-\rho^2)}\left(z_1^2 - 2\rho z_1 z_2 + z_2^2\right) + \frac{1}{2}\left(z_1^2 + z_2^2\right)
$$

This expression is derived from the bivariate normal density minus the product of marginal standard normal densities:

$$
c(u, v; \rho) = \frac{\phi_2(z_1, z_2; \rho)}{\phi(z_1)\phi(z_2)}
$$

where $\phi_2(\cdot, \cdot; \rho)$ is the bivariate standard normal density with correlation $\rho$, and $\phi(\cdot)$ is the univariate standard normal density.

::: {.callout-note}
## Numerical Stability: Boundary Clamping

The quantile function $\Phi^{-1}(u)$ diverges as $u \to 0$ or $u \to 1$. To prevent numerical overflow, the implementation applies boundary clamping:

$$
u_{\text{clamped}} = \max(\varepsilon, \min(1 - \varepsilon, u)), \quad \varepsilon = 10^{-9}
$$

This affects only observations beyond the $0.9999999$th percentile and has negligible impact on inference. The Stan implementation:

```stan
real gaussian_copula_ld(real u, real v, real rho) {
  real eps = 1e-9;
  real uu  = fmax(eps, fmin(1 - eps, u));
  real vv  = fmax(eps, fmin(1 - eps, v));
  real z1  = inv_Phi(uu);
  real z2  = inv_Phi(vv);
  real rho2 = square(rho);
  
  return -0.5 * log1m(rho2)
         - 0.5 / (1 - rho2) * (square(z1) - 2 * rho * z1 * z2 + square(z2))
         + 0.5 * (square(z1) + square(z2));
}
```
:::

## 10.4. Chi-Squared Mirroring for Left-Skewed Marginals

The `extremeCHI` condition generates innovations from standardized $\chi^2_1$ distributions. For left-skewed marginals (directions `--` and `+-`), the distribution must be mirrored while preserving the copula correlation structure.

**Naive approach (incorrect):** Given $U \sim \text{Uniform}(0,1)$ from the copula, compute $-F^{-1}_{\chi^2}(U)$ to obtain left-skewed draws.

This approach flips the sign of the copula correlation. If $\rho > 0$, large $U_1$ tends to co-occur with large $U_2$. Under the naive mirroring, large $U_1$ maps to large negative $\epsilon_1$, but large $U_2$ maps to large positive $\epsilon_2$, reversing the dependence.

For the mirrored (left-skewed) marginal, we instead use the quantile function of $-X$:

$$
Q_{-X}(u) = -Q_X(1 - u)
$$

This transforms the uniform *before* applying the quantile function, preserving the copula structure:

```r
# Correct implementation in simulate_data.R
function(pu) {
  # Adjust uniform first if mirroring
  pu_adj <- if (mirror) 1 - pu else pu
  x_raw <- qchisq(pu_adj, df)
  x_std <- (x_raw - mean_chi) / sd_chi
  # negate for left-skewed distribution
  if (mirror) -x_std else x_std
}
```

With this implementation, the copula parameter $\rho$ is preserved across directions, so bias and coverage summaries use the input $\rho$ directly (can be checked with Kendalls Tau).

<!-- ::: {.callout-important} -->
<!-- ## Verification via Kendall's Tau -->

<!-- The simulation pipeline verifies copula correlation preservation by computing empirical Kendall's $\tau$ on generated residuals: -->

<!-- $$ -->
<!-- \tau_{\text{expected}} = \frac{2}{\pi} \arcsin(\rho) -->
<!-- $$ -->

<!-- For a Gaussian copula with $\rho = 0.5$, this yields $\tau \approx 0.333$. The pipeline flags conditions where $|\tau_{\text{empirical}} - \tau_{\text{expected}}|$ exceeds $3 \times \text{SE}(\tau)$, where $\text{SE}(\tau) \approx \sqrt{2(2n+5)/(9n(n-1))}$ for sample size $n$. -->
<!-- ::: -->

## 10.5. Centered Parameterization for Skew-Normal Marginals

The SG model uses a centered parameterization that enforces zero-mean innovations by construction. This section documents the transformation from CP parameters $(\delta, \omega)$ to the direct parameterization $(\xi, \omega, \alpha)$ required by Stan's `skew_normal` functions.

### Parameterization Relationship

The skew-normal distribution $\text{SN}(\xi, \omega, \alpha)$ has:

- Location: $\xi \in \mathbb{R}$
- Scale: $\omega > 0$
- Shape: $\alpha \in \mathbb{R}$

The derived parameter $\delta$ relates to $\alpha$ via:

$$
\delta = \frac{\alpha}{\sqrt{1 + \alpha^2}} \in (-1, 1)
$$

with inverse:

$$
\alpha = \frac{\delta}{\sqrt{1 - \delta^2}}
$$

### Centering Constraint

The mean of $\text{SN}(\xi, \omega, \alpha)$ is:

$$
\mathbb{E}[X] = \xi + \omega \delta \sqrt{\frac{2}{\pi}}
$$

To enforce $\mathbb{E}[\epsilon] = 0$, we set:

$$
\xi = -\omega \delta \sqrt{\frac{2}{\pi}}
$$

### Stan Implementation

The SG model estimates $(\delta, \omega)$ directly and computes $(\xi, \alpha)$ as transformed parameters:

```stan
transformed parameters {
  vector[2] alpha;
  vector[2] xi;
  
  // transform delta -> alpha
  alpha = delta ./ sqrt(1 - square(delta));
  
  // compute centering location
  xi = -omega .* (delta * sqrt(2.0 / pi()));
}
```

<!-- ::: {.callout-note} -->
<!-- ## Why Estimate $\delta$ Instead of $\alpha$? -->

<!-- The parameter $\delta \in (-1, 1)$ is bounded, which facilitates prior specification and avoids the unbounded support of $\alpha \in \mathbb{R}$. As $|\alpha| \to \infty$, $|\delta| \to 1$, and small changes in $\delta$ near the boundary correspond to large changes in $\alpha$. The prior $\delta \sim \text{Normal}(0, 0.5)$ (truncated to $(-1,1)$) regularizes toward symmetry while permitting substantial skewness. -->
<!-- ::: -->

### Variance Under the Centered Parameterization

The variance of $\text{SN}(\xi, \omega, \alpha)$ is:

$$
\text{Var}(X) = \omega^2 \left(1 - \frac{2\delta^2}{\pi}\right)
$$

In the DGP, we fix $\text{Var}(\epsilon) = 1$ by setting $\omega = (1 - 2\delta^2/\pi)^{-1/2}$. In the SG model, $\omega$ is estimated freely (see Section 1.1, Note on "SG Model Parameterization: Variance Not Fixed").

## 10.6. Reproducibility Strategy

The simulation study employs deterministic seeding to ensure full reproducibility regardless of execution order, parallelization, or resumption after interruption.


```{r export_tables}
#| label: export_tables
#| echo: false

# 1. Main Condition-Level Summary (Aggregated across all successful runs)
export_cond <- cond_summary |>
  select(
    Model, param, skew_level, direction, T,
    rho, VARset,
    N_valid,
    mean_rel_bias, coverage_95, RMSE,
    mean_post_sd, emp_sd, sd_bias,
    mean_bias
  )

write_csv(export_cond, file.path(EXPORT_DIR, "analysis_summary_aggregated.csv"))

# 2. Status-Split Summary (Aggregated within Clean/Problematic groups)
export_status <- cond_status |>
  select(Model, param, mcmc_status,
    skew_level, direction, T,
    rho = rho_val, VARset = VARset_val,
    N_valid,
    mean_rel_bias, coverage_95, RMSE,
    mean_post_sd, emp_sd, sd_bias
  )

write_csv(export_status, file.path(EXPORT_DIR, "analysis_summary_status_split.csv"))

# 3. MCMC Health Summary (Counts)
mcmc_health_export <- mcmc_summary |>
  pivot_wider(names_from = mcmc_status, values_from = Count, values_fill = list(Count = 0)) |>
  arrange(Model, skew_level, T)

write_csv(mcmc_health_export, file.path(EXPORT_DIR, "analysis_mcmc_health_counts.csv"))
```
