---
title: "SEM Skewness Study: Indicator vs. Latent (Exponential Margins, Gaussian Copula)"
format:
  html:
    toc: true
    toc-depth: 3
    code-fold: true
    theme: lumen
    self-contained: true
  pdf:
    toc: true
    toc-depth: 3
execute:
  warning: false
  message: false
---

```{r}
#| label: setup
suppressPackageStartupMessages({
  library(dplyr)
  library(tidyr)
  library(readr)
  library(ggplot2)
  library(stringr)
  library(knitr)
})

# Paths for the SEM study
DATA_DIR   <- "data"
RES_DIR    <- "results_sem"
EXPORT_DIR <- file.path(RES_DIR, "exported_tables")
dir.create(EXPORT_DIR, showWarnings = FALSE, recursive = TRUE)

files <- list(
  cond   = file.path(RES_DIR,  "summary_conditions_sem.csv"),
  rep    = file.path(RES_DIR,  "summary_replications_sem.csv"),
  design = file.path(DATA_DIR, "sim_conditions_sem.rds")
)

if (!all(file.exists(unlist(files)))) {
  stop("Missing input(s): expecting results_sem/summary_*.csv and data/sim_conditions_sem.rds. ",
       "Please run analysis_sem.R first.")
}

# Load design and summaries
design <- readRDS(files$design) |>
  dplyr::select(condition_id, sem_study, direction, `T`, rho)


cond_raw <- read_csv(files$cond, show_col_types = FALSE)
rep_raw  <- read_csv(files$rep,  show_col_types = FALSE)

# Join design fields onto the summaries
cond   <- cond_raw |> left_join(design, by = "condition_id")
rep_df <- rep_raw  |> filter(!is.na(param)) |> left_join(design, by = "condition_id")

# Make "n" (= T) numeric for plotting on the x-axis
rep_df <- rep_df |> mutate(n = as.numeric(T))
cond   <- cond   |> mutate(n = as.numeric(T))

# Factor labels from the actual design (no hard-coding)
dir_levels <- unique(design$direction) |> as.character() |> sort()
rho_levels <- unique(design$rho)       |> as.character() |> sort()
T_levels   <- unique(design$T)         |> as.character() |> sort()

model_labs <- c(EI = "Indicator-skew (EI)", EL = "Latent-skew (EL)")

rep_df <- rep_df |>
  mutate(
    Model = factor(model, levels = c("EI","EL"), labels = model_labs),
    sem_study = factor(sem_study, levels = c("A_indicator","B_latent"),
                       labels = c("A: indicator-skew","B: latent-skew")),
    T  = factor(T,  levels = T_levels),
    rho = factor(rho, levels = rho_levels),
    direction = factor(direction, levels = dir_levels)
  )

cond <- cond |>
  mutate(
    Model = factor(model, levels = c("EI","EL"), labels = model_labs),
    sem_study = factor(sem_study, levels = c("A_indicator","B_latent"),
                       labels = c("A: indicator-skew","B: latent-skew")),
    T  = factor(T,  levels = T_levels),
    rho = factor(rho, levels = rho_levels),
    direction = factor(direction, levels = dir_levels)
  )

# Parameter groups
core_params  <- c("mu[1]","mu[2]","phi11","phi12","phi21","phi22","rho")
extra_params <- c("sigma_exp[1]","sigma_exp[2]")

# Simple ggplot theme
theme_standard <- theme_bw(base_size = 13)

`%||%` <- function(a,b) if (!is.null(a)) a else b
```

# 0. tl;dr

**Question.** How do estimates and uncertainty behave when **skewness lives at different layers** of a SEM/VAR(1)?

* **Study A (EI):** skewed **measurement errors** (exponential margins), Gaussian state
* **Study B (EL):** skewed **state innovations** (exponential margins), no measurement error

**Key expectations (to confirm with the figures below):**

* **Layer matters.** When fitted at the correct layer, both EI and EL should recover the VAR dynamics ($\Phi$) and intercepts ($\mu$) well at typical lengths such as $T=100$.
* **($\rho$) sensitivity.** The Gaussian copula correlation ($\rho$) is estimated on the **active layer**; misspecifying the layer (fitting EI to EL data or vice versa) tends to attenuate ($\hat{\rho}$).
* **Diagnostics vs. inference.** Occasional divergences (near one-sided bounds) need not imply poor inference for ($\Phi$) or ($\mu$); still examine coverage by parameter.

# 1. Introduction

We compare two bivariate SEM/VAR(1) formulations with **exponential one-sided margins** and a **Gaussian copula**:

* **EI (indicator-skew):**
  $$
  \mathbf s_t=\boldsymbol\mu+\mathbf B,\mathbf s_{t-1}+\boldsymbol\eta_t,\quad
  \boldsymbol\eta_t\sim\mathcal N(\mathbf 0,\mathbf I),\qquad
  \mathbf y_t=\mathbf s_t+\boldsymbol\varepsilon_t.
  $$
  Skewness and ($\rho$) live in ($\boldsymbol\varepsilon_t$).

* **EL (latent-skew):**
  $$
  \mathbf y_t=\boldsymbol\mu+\mathbf B,\mathbf y_{t-1}+\boldsymbol\zeta_t.
  $$
  Skewness and ($\rho$) live in ($\boldsymbol\zeta_t$).

Each margin uses an **exponential** law with **sign** (`direction`):
right-skew ((+)): ($e \ge -s$), left-skew ((-)): ($e \le s$); true **scale** ($s=1$).
A **Gaussian copula** with correlation ($\rho$) couples the two margins at each ($t$) on the **active layer**.

## 1.1 Simulation Design

```{r}
#| label: design_table
#| echo: false

B_lab <- "$\\begin{pmatrix} 0.55 & 0.10 \\\\ 0.10 & 0.25 \\end{pmatrix}$"
n_cond <- nrow(design)

levels_str <- function(x) paste(sort(unique(x)), collapse = ", ")

design_summary <- tibble::tibble(
  Factor = c("SEM Study (active layer)",
             "Skew Direction (per margin)",
             "Copula Correlation ($\\rho$) at active layer",
             "Time Series Length ($T$) ≡ sample size $n$",
             "VAR(1) Coefficients ($\\mathbf{B}$)",
             "Replications / cell",
             "Total Conditions"),
  Levels = c("A: indicator-skew (measurement), B: latent-skew (innovations)",
             levels_str(design$direction),
             levels_str(design$rho),
             levels_str(design$T),
             paste0("Fixed as ", B_lab),
             if ("n_reps" %in% names(design)) levels_str(design$n_reps) else "varies",
             n_cond)
)

kable(design_summary, caption = "SEM study design (current grid).", escape = FALSE)
```

# 2. Data loading and preparation

```{r}
#| label: load_data

# Condition-level helper
cond <- cond |>
  mutate(RMSE = sqrt((mean_bias %||% 0)^2 + (emp_sd %||% 0)^2))

# Replication-level MCMC classification
RHAT_THRESHOLD <- 1.01
rep_df <- rep_df |>
  mutate(
    mcmc_status = dplyr::case_when(
      is.na(max_rhat) | status != "ok" ~ "Failed/Error",
      max_rhat > RHAT_THRESHOLD | (n_div %||% 0) > 0 ~ "Problematic",
      TRUE ~ "Clean"
    ),
    mcmc_status = factor(mcmc_status, levels = c("Clean","Problematic","Failed/Error"))
  )
```

## 2.1 MCMC overview (x-axis: $n$)

```{r, fig.width=12, fig.height=6}
#| label: mcmc_overview_counts

mcmc_counts <- rep_df |>
  distinct(condition_id, rep_id, Model, sem_study, direction, rho, n, mcmc_status) |>
  count(Model, sem_study, direction, rho, n, mcmc_status, name = "N")

ggplot(mcmc_counts, aes(x = n, y = N, fill = mcmc_status, group = mcmc_status)) +
  geom_col(position = "stack") +
  facet_grid(Model + sem_study ~ direction + rho, labeller = label_both) +
  scale_fill_manual(values = c("Clean"="#4daf4a","Problematic"="#ff7f00","Failed/Error"="#e41a1c")) +
  labs(title = "MCMC status counts by model / study / direction / ρ (x-axis = n)",
       x = "n (time points T)", y = "Number of replications", fill = "Status") +
  theme_standard
```

```{r, fig.width=12, fig.height=6}
#| label: mcmc_divergence_distribution

div_data <- rep_df |>
  filter(param == "rho") |>
  distinct(condition_id, rep_id, Model, sem_study, direction, rho, n, n_div, mcmc_status) |>
  filter(mcmc_status != "Failed/Error")

ggplot(div_data, aes(x = n, y = n_div, color = Model)) +
  geom_boxplot(outlier.shape = NA, alpha = 0.6) +
  geom_jitter(width = 2, alpha = 0.4, size = 1.5) +
  facet_grid(sem_study ~ direction + rho, labeller = label_both) +
  labs(title = "Divergent transitions per run (post-warmup; x-axis = n)",
       x = "n (time points T)", y = "n_div") +
  theme_standard
```

# 3. Core parameter accuracy ($\Phi$, $\mu$, $\rho$; x-axis = $n$)

We summarize **bias**, **coverage**, and **uncertainty calibration** for
${\mu_1,\mu_2,\phi_{11},\phi_{12},\phi_{21},\phi_{22},\rho}$.

```{r}
#| label: metric_helpers

plot_metric_n <- function(df, metric_col, title, ylab,
                          use_free_y = FALSE, ylims = NULL) {
  d <- df |> filter(param %in% core_params, !is.na(.data[[metric_col]]))
  if (nrow(d) == 0) return(NULL)
  p <- ggplot(d, aes(x = as.numeric(as.character(n)), y = .data[[metric_col]],
                     color = Model, group = Model)) +
    geom_line(position = position_dodge(2), linewidth = 0.8) +
    geom_point(position = position_dodge(2), size = 2.2) +
    facet_grid(param ~ sem_study + direction + rho, labeller = label_both,
               scales = ifelse(use_free_y,"free_y","fixed")) +
    labs(title = title, x = "n (time points T)", y = ylab, color = "Model") +
    theme_standard
  if (metric_col %in% c("mean_rel_bias","sd_bias")) {
    p <- p + geom_hline(yintercept = 0, linetype = "dashed", color = "grey40")
  } else if (metric_col == "coverage_95") {
    p <- p + geom_hline(yintercept = 0.95, linetype = "dashed", color = "grey40")
  }
  if (!is.null(ylims)) p <- p + coord_cartesian(ylim = ylims)
  p
}

cond_core <- cond |> filter(param %in% core_params)
```

### 3.1 Relative bias

```{r, fig.width=14, fig.height=12}
#| label: core_relbias
plot_metric_n(cond_core, "mean_rel_bias",
              "Relative bias (core parameters; x-axis = n)",
              "Mean relative bias", use_free_y = TRUE)
```

### 3.2 95% coverage

```{r, fig.width=14, fig.height=12}
#| label: core_coverage
plot_metric_n(cond_core, "coverage_95",
              "Empirical 95% coverage (core parameters; x-axis = n)",
              "Coverage", ylims = c(0.8, 1.0))
```

### 3.3 SD-bias (posterior SD – empirical SD)

```{r, fig.width=14, fig.height=12}
#| label: core_sdbias
plot_metric_n(cond_core, "sd_bias",
              "SD-bias (posterior SD − empirical SD; x-axis = n)",
              "SD-bias", use_free_y = TRUE)
```

# 4. Marginal scale parameters ($\sigma_{\exp}$; x-axis = $n$)

Both EI and EL estimate $\sigma_{\exp}$ but on different layers:
EI: **measurement error**; EL: **innovations**. Truth: $\sigma_{\exp}=1$.

```{r}
#| label: sigma_helpers

plot_metric_any_n <- function(df, metric_col, title, ylab,
                              use_free_y = FALSE, ylims = NULL) {
  d <- df |> filter(!is.na(.data[[metric_col]]))
  if (nrow(d) == 0) return(NULL)
  p <- ggplot(d, aes(x = as.numeric(as.character(n)), y = .data[[metric_col]],
                     color = Model, group = Model)) +
    geom_line(position = position_dodge(2), linewidth = 0.8) +
    geom_point(position = position_dodge(2), size = 2.2) +
    facet_grid(param ~ sem_study + direction + rho, labeller = label_both,
               scales = ifelse(use_free_y,"free_y","fixed")) +
    labs(title = title, x = "n (time points T)", y = ylab, color = "Model") +
    theme_standard
  if (metric_col %in% c("mean_rel_bias","sd_bias")) {
    p <- p + geom_hline(yintercept = 0, linetype = "dashed", color = "grey40")
  } else if (metric_col == "coverage_95") {
    p <- p + geom_hline(yintercept = 0.95, linetype = "dashed", color = "grey40")
  }
  if (!is.null(ylims)) p <- p + coord_cartesian(ylim = ylims)
  p
}
```

```{r, fig.width=14, fig.height=10}
#| label: sigma_exp_section

cond_sigma <- cond |> filter(param %in% c("sigma_exp[1]","sigma_exp[2]"))

p1 <- plot_metric_any_n(cond_sigma, "mean_rel_bias",
                        "Relative bias (sigma_exp; x-axis = n)", "Mean relative bias", use_free_y = TRUE)

p2 <- plot_metric_any_n(cond_sigma, "coverage_95",
                        "Empirical 95% coverage (sigma_exp; x-axis = n)", "Coverage", ylims = c(0.8, 1.0))

print(p1); print(p2)
```

# 5. Clean vs. Problematic (split by MCMC status; x-axis = $n$)

```{r}
#| label: aggregate_by_status

aggregate_by_status <- function(df) {
  df |>
    filter(mcmc_status != "Failed/Error", param %in% core_params) |>
    group_by(condition_id, Model, param, mcmc_status, sem_study, direction, rho, n) |>
    summarise(
      N_valid      = n(),
      mean_rel_bias= mean(rel_bias, na.rm = TRUE),
      coverage_95  = mean(cover95, na.rm = TRUE),
      mean_post_sd = mean(post_sd, na.rm = TRUE),
      emp_sd       = sd(post_mean, na.rm = TRUE),
      mean_bias    = mean(bias, na.rm = TRUE),
      .groups      = "drop"
    ) |>
    mutate(
      emp_sd = ifelse(is.na(emp_sd), 0, emp_sd),
      sd_bias = mean_post_sd - emp_sd,
      RMSE = sqrt((mean_bias %||% 0)^2 + (emp_sd %||% 0)^2)
    )
}

cond_status <- aggregate_by_status(rep_df)
```

```{r, fig.width=12, fig.height=10}
#| label: coverage_status_split

status_overview <- cond_status |>
  group_by(Model, param, sem_study, direction, rho, n, mcmc_status) |>
  summarise(mean_coverage = mean(coverage_95, na.rm = TRUE), .groups = "drop")

ggplot(status_overview,
       aes(x = as.numeric(as.character(n)), y = mean_coverage, color = mcmc_status, group = mcmc_status)) +
  geom_line(linewidth = 0.8) +
  geom_point(size = 2.2) +
  facet_grid(Model + sem_study ~ param + direction + rho, labeller = label_both) +
  geom_hline(yintercept = 0.95, linetype = "dashed", color = "grey40") +
  scale_color_manual(values = c("Clean"="#4daf4a","Problematic"="#ff7f00")) +
  labs(title = "Coverage by MCMC status (core parameters; x-axis = n)",
       x = "n (time points T)", y = "Mean coverage", color = "Status") +
  theme_standard
```

# 6. Export tidy tables

```{r}
#| label: export_tables

# 1) Main condition-level summary (with design joined)
export_cond <- cond |>
  dplyr::select(
    condition_id, Model, sem_study, direction, rho,
    n, T = any_of("T"),   # <-- quote 'T' so select() doesn't see TRUE
    param,
    N_valid, N_truth_avail,
    mean_rel_bias, coverage_95, RMSE,
    mean_post_sd, emp_sd, sd_bias,
    mean_n_div, prop_div, mean_rhat
  )

readr::write_csv(export_cond, file.path(EXPORT_DIR, "sem_analysis_conditions.csv"))

# 2) Coverage by MCMC status (core only)
export_status <- cond_status |>
  dplyr::select(
    Model, sem_study, direction, rho,
    n, T = any_of("T"),   # <-- same here
    param, mcmc_status,
    N_valid,
    mean_rel_bias, coverage_95, RMSE,
    mean_post_sd, emp_sd, sd_bias
  )

readr::write_csv(export_status, file.path(EXPORT_DIR, "sem_analysis_status_split_core.csv"))

```

# 7. Notes on interpretation

* **Layer-specific copula:** ($\rho$) is identified at the **active layer**. Fitting the “wrong” model (EI on EL data, or EL on EI data) can distort the PIT on that layer and bias ($\hat{\rho}$) toward zero (attenuation).
* **One-sided support:** exponential margins imply hard bounds (e.g., right-skew requires ($e \ge -s$)). Chains that frequently propose off-support values tend to report divergences; nevertheless, coverage for ($\Phi$) and ($\mu$) can remain adequate if mixing elsewhere is good.
* **Scales:** both EI and EL estimate ($\sigma_{\exp}[j]$) with truth (=1); bias/coverage for these parameters help diagnose whether the model is matching the marginal one-sidedness.

```

**What this does for you**
- Treats **`n := T` as the x-axis** in **every** panel (status, divergences, bias, coverage, SD-bias, sigma, and status-split).
- The **design table** reads your actual grid and prints what’s present (so it’s correct for the 8-condition setup you posted).
- Uses **your LaTeX style** ($\cdot$) throughout.
- Avoids the earlier `NULL` plots for $\sigma_{\exp}$ by using `plot_metric_any_n()` that does **not** filter to `core_params`.
```
