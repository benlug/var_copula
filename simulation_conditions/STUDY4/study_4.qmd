---
title: "Study 4: Multilevel VAR(1) with Exponential Margins — Exponential vs Gaussian Marginal Models (minimal pooling)"
format:
  pdf:
    toc: true
    toc_depth: 3
execute:
  warning: false
  message: false
---

```{r setup}
suppressPackageStartupMessages({
  library(dplyr)
  library(tidyr)
  library(readr)
  library(ggplot2)
  library(stringr)
  library(knitr)
  library(scales)
})

# Project-relative paths (kept consistent with the Study 1–3 reports)
BASE_DIR   <- file.path("simulation_conditions", "STUDY4")
DATA_DIR   <- file.path(BASE_DIR, "data")
RES_DIR    <- file.path(BASE_DIR, "results")
EXPORT_DIR <- file.path(RES_DIR, "exported_tables")
dir.create(EXPORT_DIR, showWarnings = FALSE, recursive = TRUE)

files <- list(
  design = file.path(DATA_DIR, "sim_conditions_ml.rds"),
  rep    = file.path(RES_DIR, "summary_replications_ml.csv"),
  cond   = file.path(RES_DIR, "summary_conditions_ml.csv")
)

if (!all(file.exists(unlist(files[c("rep", "cond")])))) {
  message("Missing required Study 4 inputs. Please run `run_pipeline_ml.R` and then `analysis_multilevel.R` first.")
  message("Expected files:\n- ", paste(unlist(files), collapse = "\n- "))
  if (knitr::is_html_output() || knitr::is_latex_output()) knitr::knit_exit()
}

rep_raw  <- read_csv(files$rep,  show_col_types = FALSE)
cond_raw <- read_csv(files$cond, show_col_types = FALSE)

# Optional design grid (used for design tables/labels). The report will still render without it.
design <- NULL
if (file.exists(files$design)) {
  design <- readRDS(files$design)
}

# Model labels used throughout the report
model_lab <- c(
  EG_MLmin = "EG (Exponential margins)",
  NG_MLmin = "NG (Gaussian margins)"
)

# Keep the raw summaries but standardize types where helpful.
rep_df  <- rep_raw  |> mutate(condition_id = as.integer(condition_id))
cond_df <- cond_raw |> mutate(condition_id = as.integer(condition_id))

# Fit-level table: one row per model × condition × replication.
# (Do NOT count fit statuses on the full rep_df; that would overcount by the number of parameters.)
fit_df <- rep_df |>
  distinct(model, condition_id, rep_id, status, n_div, max_rhat) |>
  mutate(model = factor(model, levels = names(model_lab), labels = unname(model_lab)))

# Attach design information (if present)
if (!is.null(design)) {
  design_aug <- design |>
    mutate(
      condition_id = as.integer(condition_id),
      N_units   = as.integer(N_units),
      T         = as.integer(T),
      burnin    = as.integer(burnin),
      rho       = as.numeric(rho),
      VARset    = as.character(VARset),
      direction = as.character(direction),
      tau_mu_1  = vapply(tau_mu, function(v) v[1], numeric(1)),
      tau_mu_2  = vapply(tau_mu, function(v) v[2], numeric(1)),
      phi11     = vapply(phi_matrix, function(M) M[1, 1], numeric(1)),
      phi12     = vapply(phi_matrix, function(M) M[1, 2], numeric(1)),
      phi21     = vapply(phi_matrix, function(M) M[2, 1], numeric(1)),
      phi22     = vapply(phi_matrix, function(M) M[2, 2], numeric(1))
    ) |>
    select(condition_id, N_units, T, burnin, rho, VARset, direction,
           tau_mu_1, tau_mu_2, phi11, phi12, phi21, phi22)

  fit_df  <- fit_df  |> left_join(design_aug, by = "condition_id")
  cond_df <- cond_df |> left_join(design_aug, by = "condition_id")
  rep_df  <- rep_df  |> left_join(design_aug, by = "condition_id")
}

# Plot theme for consistency across studies
theme_study <- function() {
  theme_minimal(base_size = 12) +
    theme(
      legend.position = "bottom",
      panel.grid.minor = element_blank(),
      axis.text.x = element_text(angle = 45, hjust = 1)
    )
}

safe_print <- function(x, msg = "(No data to display.)") {
  if (is.null(x) || (inherits(x, "data.frame") && nrow(x) == 0)) {
    cat(msg)
  } else {
    print(x)
  }
}
```

# 0. tl;dr

```{r tldr, echo=FALSE}
# Fit success rates (by model)
tldr_status <- fit_df |>
  group_by(model) |>
  summarise(
    n_fits = n(),
    ok_rate = mean(status == "ok", na.rm = TRUE),
    div_rate = mean(status == "ok" & n_div > 0, na.rm = TRUE),
    med_max_rhat = median(max_rhat[status == "ok"], na.rm = TRUE),
    .groups = "drop"
  )

# Aggregate performance on parameters shared by both models
shared_params <- c("phi11", "phi12", "phi21", "phi22", "rho",
                  "mu_bar[1]", "mu_bar[2]", "tau_mu[1]", "tau_mu[2]")

tldr_perf <- cond_df |>
  filter(param %in% shared_params, N_valid > 0) |>
  mutate(model = factor(model, levels = names(model_lab), labels = unname(model_lab))) |>
  group_by(model) |>
  summarise(
    mean_abs_bias = mean(abs(mean_bias), na.rm = TRUE),
    mean_cov95    = mean(coverage_95, na.rm = TRUE),
    .groups = "drop"
  )

safe_print(tldr_status)
cat("\n\n")
safe_print(tldr_perf)
```

## 0.1 Computational diagnostics

- The table above reports per-model fit completion rates (`status == "ok"`), the fraction of completed fits with any divergent transitions, and the median of the maximum $\widehat{R}$ across parameters.
- In this multilevel setting, divergent transitions are plausibly driven by the interaction between (i) hierarchical intercepts and (ii) the lower-bound constraint used by the exponential-margin model (see Section 5.2).

## 0.2 Statistical performance

- The second table reports mean absolute bias and mean 95% coverage across parameters shared by both models: $(\Phi,\rho,\bar\mu,\tau_\mu)$.
- The marginal scale parameters are model-specific (`sigma` for NG, `sigma_exp` for EG) and should be interpreted within each margin family rather than compared directly.

## 0.3 Practical implications

- When the estimand of interest is the VAR dynamics or copula dependence, inference can be summarized primarily through $(\Phi,\rho)$, which are common to both models.
- When the estimand of interest includes innovation scale and/or tail behavior, the margin family matters; this study quantifies that sensitivity under a standardized exponential DGP.

# 1. Introduction

## 1.1 Data-generating process

For unit $i=1,\dots,N$ and time $t=2,\dots,T$, the data are generated from a bivariate VAR(1):
$$
Y_{i,t} = \mu_i + \Phi Y_{i,t-1} + \epsilon_{i,t},
$$
where $Y_{i,t}\in\mathbb{R}^2$, $\Phi\in\mathbb{R}^{2\times 2}$ is shared across units, and $\mu_i\in\mathbb{R}^2$ is unit-specific.

The unit intercepts follow a minimal-pooling hierarchy:
$$
\mu_i \sim \mathcal{N}\!\left(\bar\mu,\; \mathrm{diag}(\tau_\mu^2)\right),
$$
with $\bar\mu=(0,0)$ in the DGP and $\tau_\mu=(\tau_{\mu,1},\tau_{\mu,2})$ varying across conditions.

Innovations $\epsilon_{i,t}$ are generated using a Gaussian copula with correlation $\rho$ and exponential margins, then standardized to mean 0 and variance 1 (per margin). Specifically, if $X\sim\mathrm{Exp}(\text{scale}=s)$, then
$$
Z = \frac{X-s}{s}
$$
has $\mathbb{E}[Z]=0$ and $\mathrm{Var}(Z)=1$; optional mirroring produces left-skew via $-Z$.

::: {.callout-note}
**Standardization and comparability**
All conditions are standardized so that the marginal innovation variance is 1. Consequently, scale parameters in fitted models have truth 1 under correct specification. Deviations from 1 reflect either finite-sample error or model misspecification.
:::

## 1.2 Simulation design

```{r design_overview, echo=FALSE}
if (is.null(design)) {
  cat("(Design file not found: `simulation_conditions/STUDY4/data/sim_conditions_ml.rds`. Skipping design tables.)")
} else {
  design_tbl <- design |>
    mutate(
      tau_mu_1 = vapply(tau_mu, function(v) v[1], numeric(1)),
      tau_mu_2 = vapply(tau_mu, function(v) v[2], numeric(1))
    ) |>
    transmute(
      condition_id,
      N_units,
      T,
      rho,
      VARset,
      direction,
      tau_mu = sprintf("(%.2f, %.2f)", tau_mu_1, tau_mu_2)
    )

  knitr::kable(design_tbl, caption = "Study 4 design grid (by condition).")
}
```

```{r phi_matrices, echo=FALSE}
if (!is.null(design) && "phi_matrix" %in% names(design)) {
  phi_by_set <- design |>
    distinct(VARset, phi_matrix) |>
    mutate(
      Phi = vapply(
        phi_matrix,
        function(M) sprintf(
          "$\\begin{pmatrix} %.2f & %.2f \\\\ %.2f & %.2f \\end{pmatrix}$",
          M[1, 1], M[1, 2], M[2, 1], M[2, 2]
        ),
        character(1)
      )
    ) |>
    select(VARset, Phi)

  knitr::kable(phi_by_set, caption = "VAR coefficient matrices by VARset.", escape = FALSE)
}
```

## 1.3 Models

Two multilevel models are fit to each simulated dataset:

- **NG_MLmin**: Gaussian margins with scale parameters `sigma[1]`, `sigma[2]` and a Gaussian copula parameter $\rho$.
- **EG_MLmin**: Exponential margins with scale parameters `sigma_exp[1]`, `sigma_exp[2]` and a Gaussian copula parameter $\rho$.

Both models share the same hierarchical intercept structure $(\bar\mu,\tau_\mu)$ and the same global VAR parameters $(\Phi,\rho)$.

# 2. Data loading and preparation

This report reads the condition-level and replication-level summaries produced by `analysis_multilevel.R`:

- `simulation_conditions/STUDY4/results/summary_replications_ml.csv`
- `simulation_conditions/STUDY4/results/summary_conditions_ml.csv`

The replication-level file contains posterior summaries and diagnostics for each fitted dataset; the condition-level file aggregates those summaries across replications within each condition.

# 3. Computational performance

## 3.1 Fit status

```{r fit_status_table, echo=FALSE}
status_tbl <- fit_df |>
  count(model, status, name = "n") |>
  group_by(model) |>
  mutate(prop = n / sum(n)) |>
  ungroup()

knitr::kable(status_tbl, caption = "Fit status counts (fit-level).")
```

```{r fit_status_plot, fig.width=7, fig.height=3.6, echo=FALSE}
ggplot(status_tbl, aes(status, n, fill = model)) +
  geom_col(position = position_dodge(width = 0.7)) +
  labs(title = "Fit statuses", x = NULL, y = "Number of fits") +
  theme_study()
```

## 3.2 Divergences and $\widehat{R}$

```{r div_rhat_plot, fig.width=7, fig.height=3.6, echo=FALSE}
ok_fits <- fit_df |> filter(status == "ok")

if (nrow(ok_fits) == 0) {
  cat("(No completed fits: status == 'ok'.)")
} else {
  p1 <- ggplot(ok_fits, aes(model, n_div)) +
    geom_boxplot(outlier.alpha = 0.3) +
    labs(title = "Divergent transitions (completed fits)", x = NULL, y = "n_div") +
    theme_study() +
    theme(axis.text.x = element_text(angle = 0, hjust = 0.5))

  p2 <- ggplot(ok_fits, aes(model, max_rhat)) +
    geom_boxplot(outlier.alpha = 0.3) +
    labs(title = "Maximum R-hat (completed fits)", x = NULL, y = "max_rhat") +
    theme_study() +
    theme(axis.text.x = element_text(angle = 0, hjust = 0.5))

  print(p1)
  print(p2)
}
```

# 4. Statistical performance

Throughout, bias and coverage are computed relative to the known truth under the DGP. Condition-level summaries report:

- `mean_bias`: average posterior mean minus truth across valid replications,
- `coverage_95`: proportion of 95% credible intervals covering the truth,
- `mean_post_sd` and `emp_sd`: mean posterior SD and empirical SD of posterior means.

## 4.1 Shared global parameters $(\Phi,\rho)$

```{r shared_globals_prep, echo=FALSE}
shared_globals <- c("phi11", "phi12", "phi21", "phi22", "rho")
shared_df <- cond_df |>
  filter(param %in% shared_globals, N_valid > 0) |>
  mutate(
    model = factor(model, levels = names(model_lab), labels = unname(model_lab)),
    param = factor(param, levels = shared_globals),
    condition_id = factor(condition_id)
  )
```

```{r shared_bias_plot, fig.width=8.5, fig.height=4.2, echo=FALSE}
if (nrow(shared_df) == 0) {
  cat("(No shared-parameter summaries found.)")
} else {
  ggplot(shared_df, aes(param, mean_bias, fill = model)) +
    geom_hline(yintercept = 0, color = "grey50") +
    geom_col(position = position_dodge(width = 0.75)) +
    facet_wrap(~ condition_id, nrow = 1) +
    labs(title = "Mean bias for shared global parameters", x = NULL, y = "Mean bias") +
    theme_study()
}
```

```{r shared_cov_plot, fig.width=8.5, fig.height=4.2, echo=FALSE}
if (nrow(shared_df) == 0) {
  cat("(No shared-parameter summaries found.)")
} else {
  ggplot(shared_df, aes(param, coverage_95, fill = model)) +
    geom_hline(yintercept = 0.95, linetype = "dashed", color = "grey40") +
    geom_col(position = position_dodge(width = 0.75)) +
    facet_wrap(~ condition_id, nrow = 1) +
    labs(title = "95% coverage for shared global parameters", x = NULL, y = "Coverage") +
    scale_y_continuous(labels = percent_format(accuracy = 1)) +
    theme_study()
}
```

## 4.2 Marginal scale parameters

The scale parameters are defined within each margin family:

- NG: `sigma[1]`, `sigma[2]` (Gaussian margins),
- EG: `sigma_exp[1]`, `sigma_exp[2]` (exponential margins with positivity constraint).

```{r scale_params_prep, echo=FALSE}
scale_params <- c("sigma[1]", "sigma[2]", "sigma_exp[1]", "sigma_exp[2]")
scale_df <- cond_df |>
  filter(param %in% scale_params, N_valid > 0) |>
  mutate(
    model = factor(model, levels = names(model_lab), labels = unname(model_lab)),
    param = factor(param, levels = scale_params),
    condition_id = factor(condition_id)
  )
```

```{r scale_bias_plot, fig.width=8.5, fig.height=4.2, echo=FALSE}
if (nrow(scale_df) == 0) {
  cat("(No scale-parameter summaries found.)")
} else {
  ggplot(scale_df, aes(param, mean_bias, fill = model)) +
    geom_hline(yintercept = 0, color = "grey50") +
    geom_col(position = position_dodge(width = 0.75)) +
    facet_wrap(~ condition_id, nrow = 1) +
    labs(title = "Mean bias for marginal scale parameters", x = NULL, y = "Mean bias") +
    theme_study()
}
```

```{r scale_cov_plot, fig.width=8.5, fig.height=4.2, echo=FALSE}
if (nrow(scale_df) == 0) {
  cat("(No scale-parameter summaries found.)")
} else {
  ggplot(scale_df, aes(param, coverage_95, fill = model)) +
    geom_hline(yintercept = 0.95, linetype = "dashed", color = "grey40") +
    geom_col(position = position_dodge(width = 0.75)) +
    facet_wrap(~ condition_id, nrow = 1) +
    labs(title = "95% coverage for marginal scale parameters", x = NULL, y = "Coverage") +
    scale_y_continuous(labels = percent_format(accuracy = 1)) +
    theme_study()
}
```

## 4.3 Hierarchical parameters $(\bar\mu,\tau_\mu)$

```{r hier_params_prep, echo=FALSE}
hier_params <- c("mu_bar[1]", "mu_bar[2]", "tau_mu[1]", "tau_mu[2]")
hier_df <- cond_df |>
  filter(param %in% hier_params, N_valid > 0) |>
  mutate(
    model = factor(model, levels = names(model_lab), labels = unname(model_lab)),
    param = factor(param, levels = hier_params),
    condition_id = factor(condition_id)
  )
```

```{r hier_bias_plot, fig.width=8.5, fig.height=4.2, echo=FALSE}
if (nrow(hier_df) == 0) {
  cat("(No hierarchical-parameter summaries found.)")
} else {
  ggplot(hier_df, aes(param, mean_bias, fill = model)) +
    geom_hline(yintercept = 0, color = "grey50") +
    geom_col(position = position_dodge(width = 0.75)) +
    facet_wrap(~ condition_id, nrow = 1) +
    labs(title = "Mean bias for hierarchical parameters", x = NULL, y = "Mean bias") +
    theme_study()
}
```

```{r hier_cov_plot, fig.width=8.5, fig.height=4.2, echo=FALSE}
if (nrow(hier_df) == 0) {
  cat("(No hierarchical-parameter summaries found.)")
} else {
  ggplot(hier_df, aes(param, coverage_95, fill = model)) +
    geom_hline(yintercept = 0.95, linetype = "dashed", color = "grey40") +
    geom_col(position = position_dodge(width = 0.75)) +
    facet_wrap(~ condition_id, nrow = 1) +
    labs(title = "95% coverage for hierarchical parameters", x = NULL, y = "Coverage") +
    scale_y_continuous(labels = percent_format(accuracy = 1)) +
    theme_study()
}
```

## 4.4 Unit-level intercepts $\mu_i$

Replication-level summaries may include unit-specific parameters `mu[1]` and `mu[2]` (per unit). The aggregation below summarizes unit-level bias and coverage across all unit-parameters encountered in the replication-level file.

```{r unit_level_summary, echo=FALSE}
has_units <- "unit" %in% names(rep_df) && any(!is.na(rep_df$unit))

if (!has_units) {
  cat("(No unit-level summaries found in `summary_replications_ml.csv`.)")
} else {
  unit_df <- rep_df |>
    filter(!is.na(unit), param %in% c("mu[1]", "mu[2]")) |>
    mutate(
      model = factor(model, levels = names(model_lab), labels = unname(model_lab)),
      condition_id = factor(condition_id)
    ) |>
    group_by(model, condition_id, param) |>
    summarise(
      mean_bias = mean(bias, na.rm = TRUE),
      coverage_95 = mean(cover95, na.rm = TRUE),
      n = n(),
      .groups = "drop"
    )

  knitr::kable(unit_df, caption = "Unit-level intercept performance (aggregated over units).")
}
```

# 5. Discussion

## 5.1 Interpretation relative to the design

- Conditions differ primarily in the heterogeneity scale $\tau_\mu$ (and, depending on the design grid, may also vary in $T$, $\rho$, or $\Phi$).
- Under the exponential DGP, EG_MLmin is correctly specified for the marginal family, whereas NG_MLmin is misspecified on the margins. A common pattern under skewness is that NG_MLmin compensates via `sigma` and can distort uncertainty quantification for shared parameters under limited sample size.

## 5.2 Important caveats and recommendations

::: {.callout-warning}
**Caveat: interpretation of `sigma_exp` in EG_MLmin**

The exponential-margin model enforces positivity through a data-dependent lower-bound construction:
$$
x_{i,t,j} = \sigma_{\text{exp},j} + s_j\,\epsilon_{i,t,j} > 0,
$$
where $s_j\in\{+1,-1\}$ encodes skew direction. Internally, $\sigma_{\text{exp},j}$ is parameterized as
$$
\sigma_{\text{exp},j} = b_j + \exp(\eta_j),
$$
with $b_j$ computed from the *current* residuals via a max operator. This implies:

1. `sigma_exp` is a composite of a feasibility bound and a slack term; it is not a free scale parameter in the same sense as `sigma` in the Gaussian-margin model.
2. The max-based bound can introduce non-smooth geometry in the posterior, increasing the risk of divergent transitions and sensitivity to tuning (e.g., `adapt_delta`).

**Recommendation.** When comparing models, treat `sigma` and `sigma_exp` as *within-model* diagnostics of marginal adequacy rather than as directly comparable estimands. For substantive comparisons, prioritize shared parameters $(\Phi,\rho,\bar\mu,\tau_\mu)$ and report computational diagnostics alongside inferential summaries.
:::

::: {.callout-note}
**Additional recommendations**

- If divergences are non-negligible in EG_MLmin, re-fit with higher `adapt_delta` and/or stronger regularization on $(\Phi,\rho)$ before interpreting bias/coverage.
- To isolate multilevel effects, expand the design grid in $N$ and $T$; estimation of $\tau_\mu$ is typically driven more by $N$ than by $T$.
:::

# 6. Reproducibility

```{r session_info, echo=FALSE}
sessionInfo()
```
