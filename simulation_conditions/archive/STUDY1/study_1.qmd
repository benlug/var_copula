---
title: "Study 1: Comparative Performance of Gaussian and Skew-Normal Copula VAR Models Under Marginal Misspecification"
format:
  html:
    toc: true
    toc_depth: 3
    code-fold: true
    theme: lumen
    self-contained: true
  pdf:
    toc: true
    toc_depth: 3
execute:
  warning: false
  message: false
---

```{r setup}
#| label: setup
# load necessary libraries
suppressPackageStartupMessages({
  library(dplyr)
  library(tidyr)
  library(readr)
  library(ggplot2)
  library(stringr)
  library(knitr)
  library(RColorBrewer)
  library(ggh4x) 
  library(sn) 
})

# define paths
# BASE_DIR <- getwd() # needed for interactive running
DATA_DIR <- file.path("data")
RES_DIR <- file.path("results")
EXPORT_DIR <- file.path(RES_DIR, "exported_tables")
dir.create(EXPORT_DIR, showWarnings = FALSE, recursive = TRUE)

files <- list(
  cond    = file.path(RES_DIR, "summary_conditions.csv"),
  rep     = file.path(RES_DIR, "summary_replications.csv"),
  design = file.path(DATA_DIR, "sim_conditions_singlelevel.rds")
)

if (!all(file.exists(unlist(files)))) {
    stop("Missing required input files. Please ensure analysis_singlelevel.R has been run.")
}
```

# 0. tl;dr

## 0.1 Computational Stability versus Statistical Inference

The Normal-Gaussian (NG) model demonstrates robust computational performance across all simulation conditions, achieving convergence without divergent transitions in all replications. In contrast, the Skew-Gaussian (SG) model exhibits increasing computational instability as marginal skewness increases, with divergence rates approaching 100% under extreme misspecification. 

However, computational diagnostics prove to be poor predictors of statistical validity: the SG model maintains comparable coverage properties for VAR dynamics ($\Phi$) regardless of MCMC status, though copula parameter ($\rho$) estimation remains severely compromised under misspecification irrespective of the model.

## 0.2 Model Performance Across Skewness Conditions

**Moderate Skewness** (`moderateSN`, $\alpha = \pm 4$): The NG model achieves statistical performance indistinguishable from the correctly specified SG model. Both exhibit negligible bias (|bias| < 0.02 for $\mu$) and maintain nominal coverage rates (~0.95). The additional computational burden of the SG model yields no discernible inferential advantage under mild departures from normality.

**Strong Skewness** (`strongSN`, $\alpha = \pm 9$): The SG model sometimes demonstrates better recovery of VAR dynamics, with relative bias reductions of 0.1-0.3 compared to NG, though coverage improvements remain small. The copula parameter $\rho$ exhibits substantial downward bias under both models, suggesting fundamental limitations of the Gaussian copula framework under severe marginal skewness.

**Extreme Misspecification** (`extremeCHI`, standardized $\chi^2_1$): Both models fail, though with distinct failure modes:
  - **VAR Dynamics ($\Phi$)**: The SG model maintains reasonable to good performance (coverage 0.90–0.97 for N≥100), while NG exhibits severe degradation
  - **Copula Parameter ($\rho$)**: Both models fail, with relative bias exceeding -1.0 under mixed-sign conditions
  - **Intercepts ($\mu$)**: The SG model exhibits substantial bias (|bias| up to 0.2), while NG remains unbiased, a consequence of the centered parameterization constraint in the SG implementation

## 0.3 Insights

The primary failure mechanism involves Probability Integral Transform (PIT) distortion arising from marginal misspecification. The NG model's scale parameter adjustments ($\sigma$ deviations ≈ ±0.025) are insufficient to accommodate heavy-tailed distributions. When assumed marginals (Normal or Skew-Normal) cannot adequately represent the true marginal behavior, the resulting non-uniform PIT systematically attenuates copula correlations and, in severe cases, induces sign reversals. Under the SG model's centered parameterization, location parameters absorb shape misspecification errors, producing the observed intercept bias while preserving dynamic parameter estimation.

# 1. Introduction

This simulation study compares the performance of two Bayesian Vector Autoregressive (VAR(1)) models: a standard Normal-Gaussian (NG) model and a Skew-Gaussian (SG) model. The study investigates how these models recover the true parameters when the data generating process (DGP) exhibits varying degrees of skewness in the innovations, coupled by a Gaussian copula.

## 1.1. Data Generating Process (DGP)

The DGP is a bivariate VAR(1) model:

$$Y_t = \mu + \Phi Y_{t-1} + \epsilon_t$$

Where $Y_t$ is a 2x1 vector of observations, $\mu$ is the intercept vector (set to 0 in this simulation), $\Phi$ is the 2x2 matrix of autoregressive coefficients, and $\epsilon_t$ is the 2x1 vector of innovations (errors).

The innovations $\epsilon_t = (\epsilon_{1,t}, \epsilon_{2,t})^T$ are generated such that they are standardized. 

::: {.callout-note}
**Standardization of the innovations**
We require innovations $\epsilon_t=(\epsilon_{1,t},\epsilon_{2,t})^\top$ to have $\mathbb{E}[\epsilon_{i,t}]=0$ and $\mathrm{Var}(\epsilon_{i,t})=1$ for all conditions. This is enforced in the DGP, and the fitted models are parameterized to be consistent with this convention.

**Skew-Normal marginals (DGP and SG model)**
Let $\mathrm{SN}(\xi,\omega,\alpha)$ denote the skew-normal with location $\xi$, scale $\omega>0$, shape $\alpha$.
$$
\delta \;=\; \frac{\alpha}{\sqrt{1+\alpha^2}}\,
$$
Moments:
$$
\mu_{\text{SN}}=\xi+\omega\,\delta\,\sqrt{\tfrac{2}{\pi}},\qquad
\sigma^2_{\text{SN}}=\omega^2\Bigl(1-\tfrac{2\delta^2}{\pi}\Bigr)
$$
To impose mean 0 and variance 1, choose
$$
\omega\;=\;\biggl(1-\frac{2\delta^2}{\pi}\biggr)^{-\tfrac12},\qquad
\xi\;=\;-\omega\,\delta\,\sqrt{\tfrac{2}{\pi}}\, 
$$
In the DGP (for `moderateSN` and `strongSN`), we set $\alpha\in\{\pm 4,\pm 9\}$, compute $\delta$, then pick $\omega,\xi$ via the formulas above so that draws from $\mathrm{SN}(\xi,\omega,\alpha)$ are standardized.

In the SG model, we use centered parameterization that re-expresses the SN so that the innovation has zero theoretical mean by construction. In practice, the Stan parameters are $(\delta,\omega)$ (or equivalent reparameterizations), and the implied $\xi$ is that value which centers the innovation at \(0\) (as above). This is why the SG model can not "use" $\mu$ to absorb the innovation mean—$\mu$ then only captures the VAR intercept, not marginal shape.

**Chi-squared marginals (DGP and NG/SG models)**
For $\chi^2_\nu$: $\mathbb{E}= \nu$, $\mathrm{Var}=2\nu$, skewness $\gamma_1=\sqrt{\tfrac{8}{\nu}}$, excess kurtosis $\gamma_2=\tfrac{12}{\nu}$.
In the DGP (for `extremeCHI`), we standardize after simulating: if $X\sim\chi^2_1$, set
$$
Z=\frac{X-1}{\sqrt{2}},\qquad \text{and (optionally) mirror as } -Z \text{ for left skew.}
$$
Thus $Z$ has mean $0$ and variance $1$ but remains skewed ($\gamma_1\approx 2.83$) and heavy-tailed ($\gamma_2=12$).
In the NG model, innovations are Gaussian with scale $\sigma$. Because the data are standardized, the truth is $\sigma=1$; deviations from 1 arise from misspecification.

In the SG model, innovations remain skew-normal with zero-mean by construction, using $(\delta,\omega)$. Under a $\chi^2$ DGP this implies misspecified marginals; the parameter $\alpha$ adjusts shape flexibly but cannot match $\chi^2_1$ skewness.
:::

::: {.callout-note}
**SG Model Parameterization: Variance Not Fixed**

The SG model estimates both scale ($\omega$) and shape ($\delta$) parameters freely, rather than constraining the innovation variance to equal 1. This apparent overparameterization is acceptable for several reasons:

1. **Bayesian identification**: In a Bayesian framework with proper priors on both $\omega$ and $\delta$, the posterior remains well-defined even without fixing variance. The data inform both parameters jointly, and the priors regularize the solution.

2. **Practical flexibility**: Fixing $\omega = f(\delta)$ to enforce unit variance would reduce model flexibility and could cause numerical issues when $|\delta| \to 1$ (where $\omega \to \infty$). The free parameterization avoids these boundary complications.

3. **Prior-induced regularization**: The half-normal prior on $\omega$ (centered near 1) and the normal prior on $\delta$ (centered at 0) together induce a prior on innovation variance that concentrates around reasonable values without hard constraints.

4. **Robustness to misspecification**: When the true DGP is not skew-normal (e.g., `extremeCHI`), the model can adjust both shape and scale to best approximate the data, rather than being forced into a potentially poor fit by the unit-variance constraint.
:::

The joint distribution of $\epsilon_t$ is modeled using a Gaussian Copula, parameterized by the correlation coefficient $\rho$. This allows the dependence structure to be modeled independently of the marginal distributions $f_i(\epsilon_{i,t})$. The joint density is given by Sklar's theorem:

$$f(\epsilon_{1,t}, \epsilon_{2,t}) = c(u_{1,t}, u_{2,t}; \rho) \cdot f_1(\epsilon_{1,t}) \cdot f_2(\epsilon_{2,t})$$
$$
f(\epsilon_{1,t}, \epsilon_{2,t}) = \underbrace{c_{\text{Gauss}}(F_1(\epsilon_{1,t}), F_2(\epsilon_{2,t}); \rho)}_{\text{Dependence Structure}} \cdot \underbrace{\frac{2}{\omega_1} \phi\left(\frac{\epsilon_{1,t}-\xi_1}{\omega_1}\right) \Phi\left(\alpha_1 \frac{\epsilon_{1,t}-\xi_1}{\omega_1}\right)}_{\text{Marginal Density for } \epsilon_1} \cdot \underbrace{\frac{2}{\omega_2} \phi\left(\frac{\epsilon_{2,t}-\xi_2}{\omega_2}\right) \Phi\left(\alpha_2 \frac{\epsilon_{2,t}-\xi_2}{\omega_2}\right)}_{\text{Marginal Density for } \epsilon_2}
$$

The marginal distributions $f_i$ are varied to introduce different levels and types of skewness.

::: {.callout-note}
**Numerical Stability in Copula Evaluation**

The Gaussian copula density requires evaluating $\Phi^{-1}(u)$ where $u = F(\epsilon)$ is the probability integral transform. When $u$ approaches 0 or 1, $\Phi^{-1}(u)$ diverges to $\pm\infty$, causing numerical overflow. To prevent this, we apply boundary clamping:
$$
u_{\text{clamped}} = \max(\varepsilon, \min(1-\varepsilon, u)), \quad \varepsilon = 10^{-9}
$$
This clamping affects only the most extreme quantiles (beyond the 0.9999999th percentile) and has negligible impact on inference. The choice of $\varepsilon = 10^{-9}$ balances numerical stability against loss of tail information—values smaller than $10^{-12}$ risk floating-point underflow, while values larger than $10^{-6}$ would noticeably compress the effective copula support.
:::

### 1.2. Simulation Design

The study employs a full factorial design crossing five factors, resulting in 108 unique conditions, with 200 replications per condition.

```{r design_table}
#| label: design_table
#| echo: false

# NOTE: Double backslashes (\\) are required here because this is inside an R string 
# that will be interpreted as LaTeX by kable(escape=FALSE).
design_summary <- tibble(
  Factor = c("Time Series Length (T)",
             "Copula Correlation ($\\rho$)",
             "VAR Parameters ($\\Phi$)",
             "",
             "Skewness Level (Marginals)",
             "",
             "",
             "Skewness Direction"),
  # For the matrix newline, we need \\\\ to produce a literal \\ in the output markdown.
  Levels = c("50, 100, 200",
             "0.30, 0.50",
             "**Set A** (Symmetric): $\\begin{pmatrix} 0.40 & 0.10 \\\\ 0.10 & 0.40 \\end{pmatrix}$",
             "**Set B** (Asymmetric): $\\begin{pmatrix} 0.55 & 0.10 \\\\ 0.10 & 0.25 \\end{pmatrix}$",
             "`moderateSN`: Skew-Normal (SN), shape $\\alpha = \\pm 4$",
             "`strongSN`: SN, shape $\\alpha = \\pm 9$",
             "`extremeCHI`: Standardized Chi-squared ($\\chi^2_1$)",
             "`++` (Both positive), `--` (Both negative), `+-` (Mixed)")
)

kable(design_summary, caption = "Summary of the Simulation Design Factors.", escape = FALSE)
```

::: {.callout-note}
**Exclusion of `-+` Direction**

The design includes directions `++`, `--`, and `+-` but excludes `-+`. This is intentional and does not reduce generality because:

1. **Symmetric VAR structure**: Both VAR parameter sets (A and B) have symmetric cross-effects ($\phi_{12} = \phi_{21}$), making the two variables exchangeable in terms of dynamics.

2. **Symmetric copula**: The Gaussian copula is symmetric in its arguments—$c(u_1, u_2; \rho) = c(u_2, u_1; \rho)$.

3. **Equivalence under relabeling**: Given these symmetries, the condition `+-` (positive skew for $Y_1$, negative for $Y_2$) is statistically equivalent to `-+` (negative for $Y_1$, positive for $Y_2$) under relabeling $Y_1 \leftrightarrow Y_2$. Including both would double computational cost without providing new information.

The `+-` condition captures all phenomena arising from mixed-sign skewness; any results would be symmetric for `-+`.
:::

### 1.3. True Parameter Values

```{r true_params_table}
#| label: true_params_table
#| echo: false

# Calculate derived SG parameters for the true values table
calc_true_sg <- function(alpha) {
  delta <- alpha / sqrt(1 + alpha^2)
  omega <- sqrt(1 / (1 - 2 * delta^2 / pi))
  list(alpha = alpha, delta = round(delta, 4), omega = round(omega, 4))
}

sg_mod <- calc_true_sg(4)
sg_strong <- calc_true_sg(9)

true_params <- tibble(
  Parameter = c("$\\mu_1, \\mu_2$", 
                "$\\phi_{11}$ (Set A / Set B)",
                "$\\phi_{12} = \\phi_{21}$",
                "$\\phi_{22}$ (Set A / Set B)",
                "$\\rho$",
                "$\\sigma_1, \\sigma_2$ (NG model)",
                "$\\alpha$ (`moderateSN`)",
                "$\\alpha$ (`strongSN`)",
                "$\\omega$ (`moderateSN`)",
                "$\\omega$ (`strongSN`)",
                "$\\alpha, \\omega$ (`extremeCHI`)"),
  `True Value` = c("0, 0",
                   "0.40 / 0.55",
                   "0.10",
                   "0.40 / 0.25",
                   "0.30 or 0.50",
                   "1.0, 1.0",
                   "$\\pm 4$ (direction-dependent)",
                   "$\\pm 9$ (direction-dependent)",
                   paste0(sg_mod$omega),
                   paste0(sg_strong$omega),
                   "Not applicable (misspecified)"),
  Notes = c("Innovations are mean-zero",
            "Diagonal AR coefficients",
            "Cross-effects (symmetric)",
            "Diagonal AR coefficients",
            "Copula correlation",
            "Innovations are unit-variance",
            "$\\delta \\approx \\pm 0.970$",
            "$\\delta \\approx \\pm 0.994$",
            "Derived from $\\alpha = \\pm 4$",
            "Derived from $\\alpha = \\pm 9$",
            "SG parameters have no true counterpart")
)

kable(true_params, caption = "True Parameter Values Used in the Data Generating Process.", escape = FALSE)
```

::: {.callout-note}
**Interpreting SG Parameters Under `extremeCHI`**

For the `extremeCHI` condition, the DGP uses standardized $\chi^2_1$ marginals, not skew-normal. Therefore, the SG model parameters $(\alpha, \omega)$ have no "true" values in the conventional sense—any estimate represents the model's best skew-normal approximation to a non-skew-normal distribution.

In the analysis, we set these truth values to `NA` and exclude them from bias/coverage calculations. When interpreting SG model fits under `extremeCHI`, the estimated $\alpha$ and $\omega$ should be understood as:

- **$\alpha$**: The skewness direction and magnitude that best approximates $\chi^2_1$ within the skew-normal family (expected to be large and positive for right-skewed conditions)
- **$\omega$**: The scale adjustment needed to match variance given the fitted shape

These estimates reflect approximation quality rather than parameter recovery.
:::


### 1.4 Visual check: standardized marginal innovations (DGP)

```{r dgp_marginal_distributions, fig.width=10, fig.height=10}
# SN parameters that enforce mean 0 and var 1 for a given alpha
sn_params <- function(alpha) {
  delta <- alpha / sqrt(1 + alpha^2)
  omega <- sqrt(1 / (1 - 2 * delta^2 / pi))       # Var = 1
  xi    <- -omega * delta * sqrt(2 / pi)          # Mean = 0
  list(xi = xi, omega = omega, alpha = alpha)
}

set.seed(2025)

# standardized chi-square draws (df = 1), both right-skewed and mirrored
rchisq_std <- function(n, df = 1, mirror = FALSE) {
  x  <- stats::rchisq(n, df = df)
  z  <- (x - df) / sqrt(2 * df)  # mean 0, var 1
  if (mirror) -z else z
}

# 20k draws per margin
draws <- list(
  "SN  alpha = +4"              = sn::rsn(20000, xi = sn_params(+4)$xi, omega = sn_params(+4)$omega, alpha = +4),
  "SN  alpha = -4"              = sn::rsn(20000, xi = sn_params(-4)$xi, omega = sn_params(-4)$omega, alpha = -4),
  "SN  alpha = +9"              = sn::rsn(20000, xi = sn_params(+9)$xi, omega = sn_params(+9)$omega, alpha = +9),
  "SN  alpha = -9"              = sn::rsn(20000, xi = sn_params(-9)$xi, omega = sn_params(-9)$omega, alpha = -9),
  "χ² df=1 (std., right)"       = rchisq_std(20000, df = 1, mirror = FALSE),
  "χ² df=1 (std., mirrored)"    = rchisq_std(20000, df = 1, mirror = TRUE)
)

df_m <- dplyr::bind_rows(lapply(names(draws), function(nm) {
  tibble::tibble(value = draws[[nm]], dist = nm)
}))

# palette
pal <- c("SN  alpha = +4"           = "#1b9e77",
         "SN  alpha = -4"           = "#1b9e77",
         "SN  alpha = +9"           = "#d95f02",
         "SN  alpha = -9"           = "#d95f02",
         "χ² df=1 (std., right)"    = "#7570b3",
         "χ² df=1 (std., mirrored)" = "#7570b3")

ggplot(df_m, aes(value)) +
  geom_histogram(aes(y = after_stat(density), fill = dist),
                 bins = 60, alpha = 0.25, colour = NA) +
  geom_density(aes(colour = dist), linewidth = 0.8) +
  # N(0,1) reference
  stat_function(fun = dnorm, linewidth = 0.7, linetype = "dashed") +
  geom_vline(xintercept = 0, linetype = "dotted") +
  scale_fill_manual(values = pal, guide = "none") +
  scale_colour_manual(values = pal, name = "") +
  facet_wrap(~ dist, scales = "free", ncol = 2) +
  theme_bw(base_size = 10) +
  labs(title = "Standardized marginal innovations used in the DGP",
       x = "value", y = "density")
```

## 2. Data Loading and Preparation

```{r load_data}
#| label: load_data

# load the design grid
design <- readRDS(files$design) |>
  select(condition_id, skew_level, direction, T, rho, VARset)

# load condition-level summary (aggregated metrics)
cond_raw <- read_csv(files$cond, show_col_types = FALSE) |>
  left_join(design, by = "condition_id")

# load replication-level summary (individual runs)
rep_raw <- read_csv(files$rep, show_col_types = FALSE) |>
    filter(!is.na(param)) |> # Filter out completely failed fits
    left_join(design, by = "condition_id")


# define parameter order and groups
param_levels <- c("omega[1]","omega[2]","alpha[1]","alpha[2]",
                  "sigma[1]","sigma[2]",
                  "mu[1]","mu[2]",
                  "phi11","phi12","phi21","phi22","rho")

# apply factor levels and clearer labels
prep_data <- function(df) {
  df |>
    mutate(param = factor(param, levels = param_levels),
           T = factor(T),
           skew_level = factor(skew_level, levels = c("moderateSN", "strongSN", "extremeCHI")),
           rho_val = rho, # keep numeric rho
           VARset_val = VARset, # keep character VARset
           # MODIFIED: Removed manual prefixes (e.g., "VARset:"). 
           # We rely on ggplot's labeller=label_both used later.
           rho = factor(rho, labels = sort(unique(df$rho))),
           VARset = factor(VARset, labels = sort(unique(df$VARset))),
           Model = factor(ifelse(model == "SG", "SG", "NG"),
                          levels = c("NG", "SG")))
}

cond <- prep_data(cond_raw)
rep_df <- prep_data(rep_raw)


cond <- cond |>
  mutate(
    # use coalesce to handle NA emp_sd if N_valid < 2
    RMSE = sqrt(mean_bias^2 + coalesce(emp_sd^2, 0))
  )


# separate core parameters (VAR dynamics, intercepts, correlation)
core_params <- c("mu[1]","mu[2]", "phi11","phi12","phi21","phi22","rho")
```

::: {.callout-note}
**Bias Metric for Intercepts ($\mu$)**

The "Relative Bias" plots display `mean_rel_bias`, defined as:
$$
\text{Relative Bias} = \frac{\hat{\theta} - \theta_{\text{true}}}{|\theta_{\text{true}}|}
$$

However, for the intercept parameters $\mu_1$ and $\mu_2$, the true value is zero, making relative bias undefined. In these cases, we report **absolute bias** instead:
$$
\text{Bias}_\mu = \hat{\mu} - 0 = \hat{\mu}
$$

This means that for $\mu$ panels in "Relative Bias" plots, the y-axis shows absolute deviation from zero (in original units), not a proportion. Cross-parameter comparisons should account for this difference in scale interpretation.
:::

### 2.1. MCMC Classification and Overview

We classify runs based on MCMC diagnostics (R-hat and divergent transitions `n_div`) and summarize the computational performance. A replication run was deemed as "Problematic" if it successfully completed sampling but exhibited either of the following conditions:

- High R-hat: The potential scale reduction factor (`max_rhat`) for any parameter was greater than 1.01.
- Divergent Transitions: The sampler reported one or more divergent transitions (`n_div > 0`) after warmup.

```{r classify_mcmc}
#| label: classify_mcmc

RHAT_THRESHOLD <- 1.01

rep_df <- rep_df |>
  mutate(
    mcmc_status = case_when(
      is.na(max_rhat) | status != "ok" ~ "Failed/Error",
      # classification based on Rhat and divergent transitions (n_div)
      max_rhat > RHAT_THRESHOLD | n_div > 0 ~ "Problematic",
      TRUE ~ "Clean"
    ),
    mcmc_status = factor(mcmc_status, levels = c("Clean", "Problematic", "Failed/Error"))
  )

# MCMC Overview Plot (Status Counts)
mcmc_summary <- rep_df |>
  distinct(condition_id, rep_id, Model, mcmc_status, T, skew_level) |>
  group_by(Model, T, skew_level, mcmc_status) |>
  summarise(Count = n(), .groups = "drop")
```

```{r mcmc_status_plot, fig.height=12, fig.width=16}
#| label: mcmc_status_plot
ggplot(mcmc_summary, aes(x = T, y = Count, fill = mcmc_status)) +
  geom_bar(stat = "identity", position = "stack") +
  facet_grid(Model ~ skew_level) +
  labs(x = "Time Series Length (T)", y = "Number of Replications", fill = "MCMC Status",
       title = "MCMC Convergence Status by Condition") +
  theme_bw(base_size = 14) +
  scale_fill_manual(values = c("Clean" = "#4daf4a", "Problematic" = "#ff7f00", "Failed/Error" = "#e41a1c"))
```

**Interpretation:**
The NG model is stable with a "Clean" MCMC status in 100% of replications across all conditions. This stability holds even when the model is statistically misspecified. In contrast, the SG model exhibits computational instability that increases with the skewness of the Data Generating Process (DGP). Under `moderateSN`, the SG model performs reasonably well, but under `strongSN`, a substantial portion of runs become "Problematic", especially at $T=50$. The `extremeCHI` condition (Chi-Squared DGP) causes severe difficulties for the SG model, resulting in nearly 100% "Problematic" runs.

```{r divergence_overview, fig.height=9, fig.width=16}
#| label: divergence_overview

# MCMC Overview Plot (Distribution of Divergent Transitions)
# we use the replication level data (rep_df) to see the distribution of n_div across individual runs.

div_dist_data <- rep_df |>
    # ensure we only look at the diagnostics once per replication run (n_div is the same for all params in a run)
    # we filter by one parameter (e.g., rho) to get unique runs, ensuring we have the n_div value for that run.
    filter(param == "rho") |>
    distinct(condition_id, rep_id, Model, T, skew_level, n_div, mcmc_status) |>
    # exclude runs that failed entirely before sampling (if any)
    filter(mcmc_status != "Failed/Error")

ggplot(div_dist_data, aes(x = T, y = n_div, fill = Model)) +
  # boxplot showing the distribution of divergences per condition
  # we hide default outliers as we will show them with jitter
  geom_boxplot(outlier.shape = NA, alpha = 0.6, position = position_dodge(width = 0.8)) +
  # jitter points to show individual runs; this helps visualize the density and outliers
  # position_jitterdodge allows jittering within the dodged groups (Models)
  geom_point(size = 1.5, alpha = 0.4, position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.8)) +
  facet_grid(Model ~ skew_level) +
  theme_bw(base_size = 14) +
  # log1p scale (log(y+1)) might be better if the distribution is highly skewed with very large outliers
  # scale_y_continuous(trans = 'log1p', breaks = c(0, 5, 50, 200)) + 
  labs(title = "Distribution of Divergent Transitions (Post-Warmup) per Replication",
       y = "Count of Divergences (n_div)",
       x = "Time Points (T)")
```

**Interpretation:**
The boxplots confirm the pattern seen in the status counts. The NG model exhibits zero divergent transitions across all conditions. The SG model, however, shows a significant number of divergences, particularly under `strongSN` and `extremeCHI`. The distribution is highly skewed, with many runs having few divergences, but a substantial number having dozens or hundreds, indicating severe sampling difficulties in those specific replications. The SG model performs better in the SN DGP conditions as T increases, but worse in the misspecified condition. 

## 3. Helpers

```{r analysis_helpers}
#| label: analysis_helpers

# standardized visualization settings
theme_standard <- theme_bw(base_size = 14) # to increase base font size
dodge_width <- 0.3

# helper function for plotting metrics across conditions
plot_metric <- function(data, metric_col, ylab, title, use_free_y = FALSE, ylims = NULL) {
  
  # filter out potential NAs (e.g. if N_truth_avail = 0)
  data_filtered <- data |> filter(!is.na(.data[[metric_col]]))
  
  if (nrow(data_filtered) == 0) {
      message("Skipping plot '", title, "' due to missing data.")
      return(NULL)
  }
  
  p <- ggplot(data_filtered, aes(x = T, y = .data[[metric_col]], color = Model, group = Model)) +
    geom_line(position = position_dodge(dodge_width), linewidth = 1) +
    geom_point(position = position_dodge(dodge_width), size = 2.5) +
    # labeller = label_both correctly adds the variable name (VARset, rho) and the value.
    facet_grid(param ~ direction + VARset + rho, labeller = label_both, scales = ifelse(use_free_y, "free_y", "fixed")) +
    theme_standard +
    labs(title = title, y = ylab, x = "Time Points (T)")
  
  # add reference lines based on the metric
  if (metric_col %in% c("mean_rel_bias", "sd_bias")) {
    p <- p + geom_hline(yintercept = 0, linetype = "dashed", color = "darkgrey")
  } else if (metric_col == "coverage_95") {
    p <- p + geom_hline(yintercept = 0.95, linetype = "dashed", color = "darkgrey")
  }
  
  # apply custom Y-axis limits if provided
  if (!is.null(ylims)) {
    p <- p + coord_cartesian(ylim = ylims)
  }
  
  return(p)
}

# wrapper to filter data and call the plotting function for a specific skew level
generate_plots_for_condition <- function(skew_lvl) {
  data_subset <- cond |>
    filter(skew_level == skew_lvl, param %in% core_params)
  
  # Adjust Y-axis limits for coverage based on the condition severity
  cov_ylims <- if (skew_lvl == "extremeCHI") c(0.5, 1.0) else c(0.8, 1.0)
  
  list(
    # Metric: Relative Bias
    bias = plot_metric(data_subset, "mean_rel_bias", "Mean Relative Bias", 
                       paste("Relative Bias (DGP:", skew_lvl, ")"), use_free_y = TRUE),
    # Metric: 95% CI Coverage
    coverage = plot_metric(data_subset, "coverage_95", "Empirical Coverage", 
                           paste("95% Coverage (DGP:", skew_lvl, ")"), ylims = cov_ylims),
    # Metric: RMSE (Overall Accuracy)
    rmse = plot_metric(data_subset, "RMSE", "Root Mean Squared Error", 
                       paste("RMSE (DGP:", skew_lvl, ")"), use_free_y = TRUE),
    # Metric: Posterior SD (Uncertainty Estimate)
    post_sd = plot_metric(data_subset, "mean_post_sd", "Mean Posterior SD", 
                          paste("Mean Posterior SD (DGP:", skew_lvl, ")"), use_free_y = TRUE),
    # Metric: SD-Bias (Calibration of Uncertainty)
    sdbias = plot_metric(data_subset, "sd_bias", "SD-Bias", 
                         paste("SD-Bias (DGP:", skew_lvl, ")"), use_free_y = TRUE)
  )
}
```

## 4. Condition 1: Moderate Skewness (moderateSN)

DGP: Skew-Normal innovations ($\alpha=4$). NG model is misspecified; SG model is correctly specified.

```{r moderateSN_plots, results="hide"}
#| label: moderateSN_plots

plots_mod <- generate_plots_for_condition("moderateSN")
```

### 4.1. Relative Bias (moderateSN)

```{r moderateSN_bias, fig.height=16, fig.width=16}
#| label: moderateSN_bias
print(plots_mod$bias)
```

### 4.2. 95% Coverage (moderateSN)

```{r moderateSN_coverage, fig.height=16, fig.width=16}
#| label: moderateSN_coverage
print(plots_mod$coverage)
```

### 4.3. SD-Bias (moderateSN)

```{r moderateSN_sdbias, fig.height=16, fig.width=16}
#| label: moderateSN_sdbias
# Note: RMSE and Mean Posterior SD plots are omitted for brevity, focusing on Bias, Coverage, and SD-Bias.
print(plots_mod$sdbias)
```

**Interpretation (moderateSN):**
Under moderate skewness, the performance of the misspecified NG model is indistinguishable from the correctly specified SG model. Both models exhibit negligible bias and maintain coverage near the nominal 95% rate for all parameters. The SD-Bias is near zero for both models. The implication is the robustness of the standard Gaussian assumption to mild violations. When departures from normality are moderate, the added complexity and computational cost of the SG model provide no discernible statistical advantage.

## 5. Condition 2: Strong Skewness (strongSN)

DGP: Skew-Normal innovations ($\alpha=9$). The misspecification for the NG model is severe.

```{r strongSN_plots, results="hide"}
#| label: strongSN_plots
plots_strong <- generate_plots_for_condition("strongSN")
```

### 5.1. Relative Bias (strongSN)

```{r strongSN_bias, fig.height=12, fig.width=16}
#| label: strongSN_bias
print(plots_strong$bias)
```

### 5.2. 95% Coverage (strongSN)

```{r strongSN_coverage, fig.height=12, fig.width=16}
#| label: strongSN_coverage
print(plots_strong$coverage)
```

### 5.3. SD-Bias (strongSN)

```{r strongSN_sdbias, fig.height=12, fig.width=16}
#| label: strongSN_sdbias
print(plots_strong$sdbias)
```

**Interpretation (strongSN):**
Under strong skewness ($\alpha = \pm 9$), meaningful differences between the NG and SG models begin to emerge, though they remain modest. The SG model shows slightly reduced bias for the VAR dynamics ($\Phi$), with typical improvements of 0.05–0.15 in relative bias compared to NG. Coverage rates for both models remain near nominal for most parameters, with the SG model showing marginally better calibration. The copula parameter $\rho$ exhibits downward bias under both models, though this is less severe than under `extremeCHI`. SD-Bias remains small for both models, indicating that posterior uncertainty quantification is reasonably well-calibrated even under strong skewness. The computational cost of the SG model (increased divergences at $T=50$) may not be justified by the modest improvements in inference, particularly for shorter time series.


## 6. Condition 3: Extreme Skewness and Misspecification (extremeCHI)

DGP: Standardized Chi-Squared ($df=1$) innovations. Highly skewed. Both models are misspecified, but flexibility of the SG model should in theory achieve better results.

```{r extremeCHI_plots, results="hide"}
#| label: extremeCHI_plots
plots_extreme <- generate_plots_for_condition("extremeCHI")
```

### 6.1. Relative Bias (extremeCHI)

```{r extremeCHI_bias, fig.height=12, fig.width=16}
#| label: extremeCHI_bias
print(plots_extreme$bias)
```

#### Interpretation: High Bias for SG Model in intercepts ($\mu_1$, $\mu_2$)

In the `extremeCHI` condition is the substantial bias in the intercepts ($\mu$) for the SG model, while the NG model remains unbiased for $\mu$. 

  * **Why NG is unbiased for $\mu$:** The NG model assumes symmetric (Normal) innovations. Estimators for the intercept are generally robust to distributional violations as long as the errors have a mean of zero (which they do in our dgp). The NG model cannot improve the fit by shifting $\mu$; instead, it distorts $\Phi$ and $\rho$.
  * **Why SG is biased for $\mu$:** This bias stems from the Centered Parameterization (CP) used in the SG model implementation. The CP stabilizes MCMC but imposes a constraint: the estimated Skew-Normal innovations must have a theoretical mean of zero. When the SG model tries to fit the highly Chi-Squared data, it struggles. The Skew-Normal shape is a poor fit for the Chi-Squared shape. To reconcile the data with this poorly fitting shape and the zero-mean constraint, the model compensates by shifting the intercept $\mu$. By biasing $\mu$, the calculated residuals ($\epsilon_t = Y_t - \text{prediction}$) are shifted, allowing a higher likelihood under the constrained Skew-Normal distribution.

The SG model sacrifices the intercept ($\mu$) to compensate for the imperfect fit between the assumed and true shapes under the constraints of the CP, thereby protecting the accuracy of the dynamics ($\Phi$) and dependence ($\rho$).

::: {.callout-note}
The `extremeCHI` condition uses standardized Chi-squared innovations with 1 degree of freedom ($\chi^2(1)$). The mismatch between this DGP and the model assumptions is strong:

| Distribution | Theoretical Skewness | Theoretical Excess Kurtosis |
| :--- | :---: | :---: |
| **True DGP ($\chi^2(1)$)** | $\approx 2.83$ | 12 |
| NG Model (Normal) | 0 | 0 |
| SG Model (Skew-Normal Max) | $\approx 0.995$ | $\approx 0.869$ |
:::

::: {.callout-note}
**Skewness and kurtosis formulas**

- $\chi^2_\nu$:
  $\mathbb{E}=\nu,\quad \mathrm{Var}=2\nu,\quad \gamma_1=\sqrt{\tfrac{8}{\nu}},\quad \gamma_2=\tfrac{12}{\nu}$ (excess).
  For $\nu=1$: $\gamma_1\approx 2.828$, $\gamma_2=12$.

- **Skew-normal** $\mathrm{SN}(\xi,\omega,\alpha)$: with $\delta=\alpha/\sqrt{1+\alpha^2}$,
  $$
  \mu=\xi+\omega\,\delta\,\sqrt{\tfrac{2}{\pi}},\quad
  \sigma^2=\omega^2\Bigl(1-\tfrac{2\delta^2}{\pi}\Bigr),
  $$
  $$
  \gamma_1
  = \frac{(4-\pi)}{2}\;
    \frac{\bigl(\delta\sqrt{\tfrac{2}{\pi}}\bigr)^3}{\bigl(1-\tfrac{2\delta^2}{\pi}\bigr)^{3/2}},\qquad
  \gamma_2
  = 2(\pi-3)\;
    \frac{\bigl(\delta\sqrt{\tfrac{2}{\pi}}\bigr)^4}{\bigl(1-\tfrac{2\delta^2}{\pi}\bigr)^{2}} .
  $$
  As $|\alpha|\to\infty$ (i.e., $|\delta|\to 1$), the **maximum skewness** is $\gamma_1\approx 0.995$ and the **maximum excess kurtosis** is $\gamma_2\approx 0.869$. This is the basis for the entries in the table contrasting $\chi^2_1$ vs. Normal vs. Skew-Normal.
:::

**Why PIT failure happens (intuition).** The PIT maps each margin $Y$ to $U=F_{\text{assumed}}(Y)$. If $F_{\text{assumed}}=F_{\text{true}}$, then $U\sim\mathrm{Uniform}(0,1)$. Under misspecification:
- **Tail compression:** If the true data have **heavier right tails** (e.g., $\chi^2_1$) than the assumed SN/Normal, then very large $Y$ values **do not land near 1** after transformation; they are pulled back toward the center (e.g., $U\approx 0.8$ instead of $0.98$). Left tails are similarly distorted under mirroring.
- **Rank distortion:** The PIT is a *ranking* device. By compressing real extremes toward the middle, **co-extreme** events $(Y_1,Y_2)$ that truly move together in the tails no longer co-locate in the **corners** of $[0,1]^2$; instead they fall into the **interior**.

For Gaussian copulas, dependence is most visible in the *corners*. When misspecified marginals push mass away from corners, the copula "sees" less tail co-movement even if it exists in the data, and any fitted $\rho$ is forced downward. This is exactly what the $\rho$ relative-bias panels show on a $[-2,0]$ y-axis.

**Why $\rho$ is pushed toward zero (attenuation).** The joint likelihood factorizes as
$$
\prod_t c\bigl(U_{1,t},U_{2,t};\rho\bigr)\, f_1(y_{1,t})\, f_2(y_{2,t}),
$$
so only the copula term $c(\cdot\,;\rho)$ can adjust dependence. When the PIT pushes tail pairs $(U_{1,t},U_{2,t})$ toward the center $(\approx 0.5,0.5)$, the Gaussian copula density becomes less sensitive to $\rho$ (the score in $\rho$ flattens). To avoid penalizing improbable tail corners that the distorted $(U_1,U_2)$ no longer occupy, the MLE/posterior moves $\rho$ down toward 0. Hence the large negative relative bias and sub-nominal coverage for $\rho$ in `extremeCHI`, regardless of "Clean" or "Problematic" MCMC status.

### 6.2. 95% Coverage (extremeCHI)

```{r extremeCHI_coverage, fig.height=12, fig.width=16}
#| label: extremeCHI_coverage
print(plots_extreme$coverage)
```

### 6.3. SD-Bias (extremeCHI)

```{r extremeCHI_sdbias, fig.height=12, fig.width=16}
#| label: extremeCHI_sdbias
print(plots_extreme$sdbias)
```

**Interpretation (extremeCHI):**
This condition serves as a stress test, showing low performance in the NG model and some limitations in the SG model.

NG Model Failure: The NG model fails completely. It exhibits extreme bias across $\Phi$ and $\rho$.

SG Model Resilience: The SG model demonstrates significant resilience in estimating the VAR dynamics $\Phi$, maintaining relatively low bias and good coverage. This suggests that the flexibility of the SG model, even when misspecified, helps mitigate the severe distortions seen in the NG model.

Joint Failure (Dependence $\rho$): Both models fail severely in recovering the dependence parameter $\rho$, exhibiting extreme negative bias (often near or exceeding -1.0). The extreme mismatch between the assumed marginal distributions (Normal or Skew-Normal) and the true DGP (Chi-Squared) leads to a failure of the Probability Integral Transform (PIT). This distortion systematically biases the estimation of the copula parameter downwards (attenuation bias).

The Intercept Trade-off (Intercept $\mu$): The SG model exhibits large biases in the intercepts, while the NG model remains unbiased for $\mu$. This occurs because the SG model implementation (Centered Parameterization) enforces a zero-mean constraint on the innovations. To compensate for the poor fit between the assumed Skew-Normal shape and the true Chi-Squared data, the model sacrifices the intercept, shifting $\mu$ to maximize the likelihood under these constraints.

## 7. Cross-Condition Synthesis: Marginal Parameters

We examine the parameters governing the marginal distributions to understand the mechanisms driving the results.

### 7.1. NG Scale Parameter Behavior ($\sigma$)

The simulated data is standardized (Variance=1). The NG model should recover $\sigma=1$.

```{r ng_sigma_inflation, fig.height=8, fig.width=16}
#| label: ng_sigma_inflation

sigma_data <- cond |>
  filter(param %in% c("sigma[1]", "sigma[2]"), Model == "NG")

# We plot the absolute bias (mean_bias) here as the truth is 1.
ggplot(sigma_data, aes(x = T, y = mean_bias, color = skew_level, group = skew_level)) +
  geom_line(position = position_dodge(0.3), linewidth = 1) +
  geom_point(position = position_dodge(0.3), size = 2.5) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "darkgrey") +
  facet_grid(param ~ direction + VARset + rho, labeller = label_both) +
  theme_standard +
  labs(title = "NG Model: Bias for Sigma (Truth=1)",
       y = "Mean Bias (Estimate - 1)",
       x = "Time Points (T)",
       color = "DGP Skew Level")
```

**Interpretation:** 
The $\sigma$ estimates under NG show small but systematic deviations from the true value of 1 (bias $\approx \pm 0.025$). These deviations represent a byproduct of marginal misspecification: when the NG model encounters skewed or heavy-tailed innovations, it cannot capture the shape mismatch and instead makes minor adjustments to the scale parameter.

Importantly, **$\sigma$ bias is not the mechanism driving $\rho$ attenuation**. The two phenomena arise from the same root cause (marginal misspecification) but through different pathways:

- **$\sigma$ bias**: The NG model slightly adjusts scale to improve marginal likelihood under non-Gaussian data. This is a local accommodation with limited impact on other parameters.

- **$\rho$ attenuation**: Arises from PIT distortion—regardless of how well the marginal *density* fits, if the marginal *CDF* misrepresents tail probabilities, the copula receives distorted inputs. Even with $\sigma$ perfectly estimated, the PIT would still compress tail observations toward the center of $[0,1]^2$, attenuating perceived dependence.

The small magnitude of $\sigma$ bias ($\approx 2.5\%$) compared to the large $\rho$ bias (often $> 100\%$) confirms that these are parallel consequences of misspecification rather than a causal chain where $\sigma$ error propagates to $\rho$.

### 7.2. SG Shape Parameter Recovery ($\alpha$)

We examine how well the SG model recovers the true shape parameter $\alpha$ (applicable for SN conditions).

```{r sg_alpha_recovery, fig.height=8, fig.width=16}
#| label: sg_alpha_recovery

alpha_data <- cond |>
  filter(param %in% c("alpha[1]", "alpha[2]"),
         Model == "SG",
         skew_level %in% c("moderateSN", "strongSN"))

# Filter NAs in case truth was unavailable
alpha_data <- alpha_data |> filter(!is.na(mean_rel_bias))

if (nrow(alpha_data) > 0) {
    ggplot(alpha_data, aes(x = T, y = mean_rel_bias, color = skew_level, group = skew_level)) +
      geom_line(position = position_dodge(0.3), linewidth = 1) +
      geom_point(position = position_dodge(0.3), size = 2.5) +
      geom_hline(yintercept = 0, linetype = "dashed", color = "darkgrey") +
      ggh4x::facet_nested(param ~ direction + VARset + rho, labeller = label_both, scales = "free_y") +
      theme_standard +
      labs(title = "SG Model: Relative Bias for Alpha (Shape Parameter)",
           y = "Relative Bias",
           x = "Time Points (T)",
           color = "DGP Skew Level")
}
```

**Interpretation: Shape Recovery**
The SG model shows substantial bias in recovering the shape parameters ($\alpha$) at low T (T=50), often underestimating the magnitude of the skewness. However, the bias rapidly diminishes as T increases. Despite the difficulty in precisely estimating $\alpha$, the mere inclusion of the shape parameter allows the SG model to capture the non-Gaussian features sufficiently to avoid the severe biases in $\Phi$ and $\rho$ seen in the NG model.

**Why biased $\alpha$ can still help.** Two reasons:
1. **Right direction of shape.** Even if $\alpha$ is biased at $T=50$, introducing a **shape degree of freedom** lets the SG model partially align the PIT with the data—enough to keep $\Phi$ bias small and coverage near nominal in `moderateSN/strongSN` and more stable than NG in `extremeCHI`.
2. **Identification improves with $T$.** The $\alpha$ panels show bias shrinking as $T$ grows, consistent with increasing information about asymmetry. This is mirrored by improving $\Phi$ coverage for SG as $T$ increases in the SN DGPs.

## 8. Impact of MCMC Diagnostics

The SG model frequently encountered "Problematic" MCMC runs. We investigate if the statistical performance differs between "Clean" and "Problematic" runs for the SG model.

```{r reaggregate_by_status}
#| label: reaggregate_by_status

# Helper function to re-aggregate metrics, filtering by MCMC status
# It is crucial to recalculate Empirical SD, SD-Bias, and RMSE within the subgroups.
aggregate_by_status <- function(df) {
  df |>
    # Filter out total failures
    filter(mcmc_status != "Failed/Error") |>
    group_by(condition_id, Model, param, mcmc_status, T, skew_level, direction, VARset, rho, VARset_val, rho_val) |>
    summarise(
      N_valid = n(),
      mean_rel_bias = mean(rel_bias, na.rm = TRUE),
      coverage_95 = mean(cover95, na.rm = TRUE),
      # Recalculate components for SD-Bias and RMSE within the status group
      mean_post_sd = mean(post_sd, na.rm = TRUE),
      emp_sd = sd(post_mean, na.rm = TRUE),
      mean_bias = mean(bias, na.rm=TRUE),
      .groups = "drop"
    ) |>
    mutate(
        # Handle cases where N_valid=1, leading to NA emp_sd
        emp_sd = ifelse(is.na(emp_sd), 0, emp_sd),
        sd_bias = mean_post_sd - emp_sd,
        RMSE = sqrt(mean_bias^2 + emp_sd^2)
    )
}

cond_status <- aggregate_by_status(rep_df)
```

### 8.1. Coverage Split by MCMC Status (SG Model)

We visualize the coverage across all three conditions, comparing Clean vs. Problematic runs.

```{r coverage_status_split, fig.height=8, fig.width=16}
#| label: coverage_status_split

status_comparison_data <- cond_status |>
  filter(Model == "SG",
         param %in% core_params)

# We focus the visualization on the interaction between T, Status, and Skew Level
# We average over VARset, rho, and direction for a clearer overview
status_overview <- status_comparison_data |>
  group_by(T, param, skew_level, mcmc_status) |>
  summarise(mean_coverage = mean(coverage_95, na.rm = TRUE), .groups = 'drop')


ggplot(status_overview,
       aes(x = T, y = mean_coverage, color = mcmc_status, group = mcmc_status)) +
  geom_line(position = position_dodge(0.3), linewidth = 1) +
  geom_point(position = position_dodge(0.3), size = 2.5) +
  geom_hline(yintercept = 0.95, linetype = "dashed", color = "darkgrey") +
  # Facet by parameter and skew level
  facet_grid(param ~ skew_level) +
  theme_standard +
  labs(title = "SG Model Coverage: Clean vs. Problematic Runs Across Conditions",
       y = "Average Empirical Coverage",
       x = "Time Points (T)",
       color = "MCMC Status") +
  coord_cartesian(ylim = c(0.8, 1.0))
```

**Interpretation: Impact of MCMC Status**
A crucial insight is the robustness of the SG model's inference to its MCMC issues. The statistical performance (coverage) of the SG model is remarkably similar between "Clean" and "Problematic" runs across all conditions. Even in the `extremeCHI` condition, where nearly all runs were problematic, coverage remains close to the nominal rate for the dynamic parameters (though coverage for $\mu$ is poor due to the bias discussed in Section 6). This suggests that while the sampler encountered difficulties (e.g., divergences), the resulting posterior draws still provided valid statistical inference for the core VAR dynamics in this study.

### 8.2. Relationship between Bias and Divergences

We examine if runs with more divergences exhibit higher bias at the replication level. We focus on the SG model under `strongSN` conditions.

```{r bias_vs_divergences, fig.height=12, fig.width=16}
#| label: bias_vs_divergences

div_bias_data <- rep_df |>
  filter(Model == "SG",
         skew_level == "strongSN",
         param %in% core_params,
         mcmc_status != "Failed/Error")

# Use absolute bias for comparison
ggplot(div_bias_data, aes(x = n_div, y = abs(bias))) +
  geom_point(alpha = 0.3, position = position_jitter(width = 0.2), size = 2) +
  # Use a generalized additive model (gam) for smoothing to capture non-linear relationships
  geom_smooth(method = "gam", color = "red", linewidth = 1.5) +
  facet_grid(param ~ T, scales = "free") +
  theme_standard +
  labs(title = "Absolute Bias vs. Divergences (SG Model, strongSN)",
       x = "Number of Divergent Transitions (n_div)",
       y = "Absolute Bias")

```

**Interpretation: Bias vs. Divergences**
There does not appear to be a strong correlation between the number of divergences and the absolute bias for the core parameters. High bias occurs in runs with few divergences, and low bias occurs in runs with many divergences. This reinforces the conclusion that MCMC diagnostics, while important indicators of computational issues, are not reliable predictors of statistical accuracy in this context.

## 9. Exporting Key Tables

```{r export_tables}
#| label: export_tables

# 1. Main Condition-Level Summary (Aggregated across all successful runs)
# This table includes all metrics (Bias, Coverage, SD-Bias, RMSE, Posterior SD, Divergences)
# aggregated by condition, model, and parameter.

export_cond <- cond |>
  # Select relevant columns and restore original factor values for clarity
  select(condition_id, Model, param, skew_level, direction, T, 
         rho = rho_val, VARset = VARset_val,
         N_valid, N_truth_avail, 
         mean_rel_bias, coverage_95, RMSE,
         mean_post_sd, emp_sd, sd_bias, 
         mean_n_div, prop_div, mean_rhat)

write_csv(export_cond, file.path(EXPORT_DIR, "analysis_summary_aggregated.csv"))
# message("Exported aggregated summary to: ", file.path(EXPORT_DIR, "analysis_summary_aggregated.csv"))


# 2. Status-Split Summary (Aggregated within Clean/Problematic groups)
# This table allows for analyzing the impact of MCMC diagnostics on performance.

export_status <- cond_status |>
    # Select relevant columns
  select(condition_id, Model, param, mcmc_status, 
         skew_level, direction, T, 
         rho = rho_val, VARset = VARset_val,
         N_valid, 
         mean_rel_bias, coverage_95, RMSE,
         mean_post_sd, emp_sd, sd_bias)

write_csv(export_status, file.path(EXPORT_DIR, "analysis_summary_status_split.csv"))
# message("Exported status-split summary to: ", file.path(EXPORT_DIR, "analysis_summary_status_split.csv"))

# 3. MCMC Health Summary (Counts)
mcmc_health_export <- mcmc_summary |>
  pivot_wider(names_from = mcmc_status, values_from = Count, values_fill = list(Count = 0)) |>
  arrange(Model, skew_level, T)

write_csv(mcmc_health_export, file.path(EXPORT_DIR, "analysis_mcmc_health_counts.csv"))
# message("Exported MCMC health counts to: ", file.path(EXPORT_DIR, "analysis_mcmc_health_counts.csv"))

```
